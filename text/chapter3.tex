%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapter 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Basis Functions\label{chapter:3}}
    Basis sets, the fundamental objects used in describing pretty much
    everything, anything from a coordinate system to an abstract vector-space
    or function-space are all part of the same set which we refer to as a
    basis. It is a set of objects applied to systems in order to essentially
    change our view of them, to extract desirable properties and to describe
    them in a rigidly fashion. In quantum mechanics the abstract vector-space
    models are used and the functions in mind are the wavefunctions thrown into
    the Schr√∂dinger equation and the space at hand is the \txtit{Hilbert
    Space}.  These functions are the central part of the particle-description
    in which quantum theory bases itself in, as such the choice of a basis is
    of monumental importance when solving quantum mechanical systems.
    Often\footnote{Read always} the choice of basis functions determine the
    efficiency and degree of usefulness that a specific method actually holds.
    This is usually to such degree that a poor choice of basis renders the
    method in question less useful or even completely unavailing.

    We will in this chapter mention some popular basis-sets used in atomic
    physics and deepen into a particular set of functions called
    \txtit{Gaussian Type orbitals} and use them with the well known
    \txtit{Hermite functions} and make a detailed calculation of the integral
    elements used in the Hartree-Fock method. These integrals have been
    calculated in polar coordinates directly before\cite{anisimovas}, the
    motivation for calculating the integrals elements in Cartesian is due to
    the double-well potential, because of the higher order monomials in which
    they can be defined by the symmetry in polar coordinates is broken making
    the polar approach less desirable. The procedure in building the basis for
    the double-well system is also explained detail.

\section{Hermite Functions}
    Hermite functions are functions of the following form
        \begin{equation}
            \phi^a_n(\blds{r}) \equiv \prod_d N_d
            H_{n_d}(\sqrt{a}x_d)\exp(-\frac{a}{2}x^2_d)
            \label{eq:HermiteFunc}
        \end{equation}
    with $\blds{r} = \sum\limits_d \blds{\me}_dx_d$ and the sum over $d$ being
    the sum over the number of dimensions and the $H_n$ is the Hermite
    polynomial of order $n$. The integer $n_d$ is the order of the
    function\footnote{In quantum mechanics the number $n$ is referred to as the
    principal quantum number and is associated with the energy of a given
    orbital(energy-level) of the system.} while the parameter $a$ is a scaling
    factor and $N_d$ is a normalization factor. These functions show up as
    eigenfunctions for the \txtit{quantum harmonic oscillator
    system}\cite{GriffQuan} with the scaling parameter $a$ equal to the
    oscillator frequency ($\omega$) of the system.

    The Hermite functions are orthogonal and give a good ansatz for the VMC
    method, see \Arf{sec:QMC}, with the scaling parameter transformed with an
    additional variational parameter. The problem with these are however that
    the matrix-elements introduced in the Hartree-Fock method
    (\Arf{sec:HFtheory}) are not solvable directly with the Hermite functions
    as basis functions. However, we can write the Hermite functions in terms of
    \txtit{Hermite-Gaussians}. See \Arf{sec:hermiteGaussFunc}.

\section{Gaussian Type Orbitals}
    \txtit{Gaussian Type Orbitals} or GTO's are functions of the following
    form\cite{HelgakerMolElcTheory}
        \begin{equation}
            G_n(\blds{\alpha};\blds{r},\blds{A}) \equiv \prod_d (x_d-A_d)^{n_d}
            \me^{-\alpha_d (x_d-A_d)^2}
            \label{eq:GTOdef1d}
        \end{equation}
    We call $\alpha$ for the scaling parameter and $i$ for the order of the
    GTO. The variable $A$ is where the function is centered. These are in many
    literatures referred to as \txtit{primitive Gaussians} and they alone
    make a poor approximation to the true wave function.

    In atomic physics these functions are used directly as a linear combination
    referred to as \txtit{contracted Gaussian functions}. These are written as
        \begin{equation}
            G_k(x, A) \equiv \sum\limits^P_{a_k=0} C_{a_k}
            G_{a_k}(\alpha_{a_k};x, A)
        \end{equation}
    and are fitted\footnote{Meaning we find the parameters $C_{a_k}.$ and
    $\alpha_{a_k}$} to \txtit{Slater-type orbitals}, which are functions with
    decaying properties(present in atomic systems), or found by some variational
    method before-hand. \\

    These functions are unfortunately not orthogonal, but they behave nicely in
    integrals and actually give an analytic expression for the
    interaction-elements mentioned in \Arf{sec:HFtheory}. For this reason we
    will go forth and use the Gaussian contracted functions and actually fit
    them to Hermite functions.

\subsection{Hermite-Gaussian Functions\label{sec:hermiteGaussFunc}}
    The GTO's described can be explicitly expressed in terms of so-called
    \txtit{Hermite-Gaussian functions}\footnote{The reason for the name is that
    the polynomial factors generated by the differentiation are precisely the
    Hermite polynomials.} defined as
        \begin{equation}
            g_n(\blds{\alpha};\blds{r},\blds{A}) = \prod_d
            \prdp{A_d}{n_d} \me^{-\alpha_d(x_d-A_d)^2}
        \end{equation}
    meaning
        \begin{equation}
            G_n(\blds{\alpha;\blds{r},\blds{A}}) = \prod_d
            (2\alpha_d)^{-n_d}\prdp{A_d}{n_d} \me^{-\alpha_d(x_d-A_d)^2}
        \end{equation}
    Some properties of the one-dimensional Hermite-Gaussians are as follows
        \begin{equation}
            \begin{aligned}
                \prd{A_x}[g_t] &= g_{t+1} \\
                g_{t+1} &= \prdp{A_x}{t}\prd{A_x}[g_0] =
                2\alpha(x-A_x)\prdp{A_x}{t}g_0 \\
                g_{t+1} &= 2\alpha((x-A_x)g_t - tg_{t-1}) \\
                (x-A_x)g_t &= \frac{1}{2\alpha}g_{t+1} + tg_{t-1}
            \end{aligned}
            \label{eq:hermiteGaussProp}
        \end{equation}
    The mentioned rewriting of the Hermite functions in terms of the
    Hermite-Gaussians is
        \begin{equation}
            \phi^a_n(\blds{r}) = \prod_d N_d \sum\limits^{n_d}_{l=0} C_{n_dl}
            g_l\left(\frac{\blds{\alpha}}{2},\blds{r},\blds{A}\right)
        \end{equation}
    with $C_{n_dl}$ being the $l'th$ Hermite-coefficient for the Hermite
    polynomial of order $n_d$. This means that the matrix-elements in
    Hartree-Fock is just a linear combination over integrals over
    Hermite-Gaussians. The following section will tackle this in detail for the
    two-dimensional case. The three-dimensional case is given by an excellent
    text by Trygve Helgaker and Peter R. Taylor\cite{HelgakerTaylorGauss}, see
    also \cite{HelgakerGauss}.

\section{Integral Elements}
    In the Hartree-Fock scheme described in \Arf{chapter:3} we need to
    calculate the integrals which define the different matrix elements. The
    integrals to be found are of the following form
        \begin{equation}
            \begin{aligned}
                \Braket{i|j} &= \infint g_i(\alpha_i;r,A)g_j(\alpha_j;r,B) \md
                \blds{r} \\
                \Braket{i|x^k_d|j} &= \infint g_i(\alpha_i;r,A) r^k
                g_j(\alpha_j;r,B) \md \blds{r} \\
                \Braket{i|\nabla^2|j} &= \infint g_i(\alpha_i;r,A)\nabla^2
                g_j(\alpha_j;r,B) \md \blds{r} \\
                \Braket{ij|\frac{1}{r}|kl} &= \infint\infint
                g_i(\alpha_i;r_1,A)g_j(\alpha_j;r_2,B) \frac{1}{r_{12}}
                g_k(\alpha_k;r_1,C)g_l(\alpha_l;r_2,D) \md \blds{r}_1 \md
                \blds{r}_2\\
            \end{aligned}
        \end{equation}
    where $\md\blds{r}$ means integration over all dimensions and with the
    $g$'s being the usual \txtit{Hermite-Gaussians} defined as
        \begin{equation}
            g_n(\alpha;\blds{r},\blds{A}) = \prod_d (x_d-A_d)^{n_d}
            \me^{-\alpha (x_d-A_d)^2}
            \label{eq:hermiteGauss2}
        \end{equation}
    We will in this chapter limit ourselves to work with isotropic Gaussians
    (meaning $\alpha_d$ is the same for all dimensions) as this will yield a
    simpler closed-form solution to the integrals. For a calculation of
    integral elements using non-isotropic Gaussian functions see this wonderful
    article \cite{nonIsoGauss}, this article takes gives a detailed
    calculations of integrals over s-type non-isotropic gaussians. The
    extension to general Gauss-Hermites can be done in the exact same manner as
    presented here, however the proportionality factors involved in the
    recursive relation is different. \\

    Before we throw ourselves out into the integrals, let us first express the
    Hermite-Gaussians in a more convenient way(again see
    \cite{HelgakerTaylorGauss} and \cite{HelgakerGauss}. The Gaussians can be
    expressed as
        \begin{equation}
            g_n(\alpha;\blds{r},\blds{A}) = \prod_d  \prdp{A_{x_d}}{n_d}
            \me^{-\alpha (x_d-A_d)^2} = \prod_d \prdp{A_{x_d}}{n_d}
            g_0(\alpha;\blds{r},\blds{A})
            \label{eq:centerDerGauss}
        \end{equation}
    Since the derivatives are with respect to the center variables we may pull
    them out of the integration meaning the integrals will only be over s-type
    Gaussians, greatly simplifying the calculations. With the mentioned
    simplification in mind, the problem is to find a closed-form expression for
    the integrals over s-type Gaussians.

    We also introduce the \txtit{Gaussian product rule}\footnote{Still in the
    isotropic case.} which basically states that the product of two Gaussian
    functions is just a third Gaussian centered between the center of the two.
    The expressions give
        \begin{equation}
            g_0(\alpha;\blds{r},\blds{A})g_0(\beta;\blds{r},\blds{B}) =
            K_{AB}\exp(-(\alpha+\beta)\blds{r}^2_s)
            \label{eq:gaussianProductRule}
        \end{equation}
    where
        \begin{equation}
            \begin{aligned}
                K_{AB} &\equiv \exp(-\frac{\alpha\beta}{\alpha+\beta}R^2_{AB})
                \\
                R_{AB} &= \abs{\blds{A} - \blds{B}} \\
                \blds{r_s} &= \blds{r} - \blds{P} \\
                \blds{P} &= \frac{\alpha\blds{A} +
                \beta\blds{B}}{\alpha + \beta}
            \end{aligned}
        \end{equation}
    the vector $\blds{r}_S$ is just somewhere between $\blds{A}$ and
    $\blds{B}$(We will see that $r_S$ disappears when the integration is done).
    The Gaussian product rule greatly simplifies the integral over two Gaussian
    functions since we can just pull $K_{AB}$ out of the integration since it
    is a constant.

\subsection{Overlap Distribution}
    An \txtit{overlap distribution} is defined as the product between two
    Hermite-Gaussian functions, that is
        \begin{equation}
            \Omega_{ij} = \prod_d g_{i_d}(x_d,\alpha,A_d)g_{j_d}(x_d,\beta,B_d)
            =
            K_{A_dB_d}x_A^{i_d}x_B^{j_d}\me^{-(\alpha+\beta)x^2_P}
        \end{equation}
    with the Gaussian product rule, which is just another Gaussian function
    centered in $P$, but with the extra \txtit{monomial} factors in
    $\blds{r}-\blds{A}$ and $\blds{r}-\blds{B}$. These factors are troublesome
    when integrating. With the motivation that Hermite-Gaussians make life
    simpler, we expand the overlap distribution in a Hermite-Gaussian basis.
    Following T. Helgaker\cite{HelgakerTaylorGauss} and working in one
    dimension(since Hermite-Gaussians can be split in each respective
    dimension) we have\footnote{The indices $i$ and $j$ are now in 1
    dimension!}
        \begin{equation}
            \Omega_{ij}(\alpha,\beta,\blds{r},\blds{A},\blds{B}) =
            \sum\limits^{i+j}_{t=0} E^{ij}_tg_t(\alpha,\beta,\blds{r},\blds{P})
            \label{eq:omegaDef}
        \end{equation}
    Again, we stress that the indices in \Arf{eq:omegaDef} and the calculations
    further are in 1 dimension. Explicit expressions for the coefficients
    $E^{ij}_t$ are difficult to derive, however a set of recurrence relations
    are possible to find using the properties of the Hermite-Gaussian
    functions. Consider firstly the incremented distribution
        \begin{align}
            \Omega_{i+1,j} &= \sum^{i+1+j}_{t=0} E^{i+1,j}_tg_t \nonumber \\
            &= \left(x_P -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)\right)\Omega_{ij} \nonumber \\
            &= \suml{t=0}{i+j} E^{ij}_t\left(x_P -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)\right) g_t \nonumber \\
            &= \suml{t=0}{i+j} E^{ij}_t\left(\left(tg_{t-1} +
            \frac{1}{2(\alpha+\beta)}g_{t+1}\right) -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)g_t\right) \nonumber \\
            &= \suml{t=0}{i+j} \left((t+1)E^{ij}_{t+1} +
            \frac{1}{2(\alpha+\beta)}E^{ij}_{j-1} -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)\right)g_t
            \label{eq:omegaIncr}
        \end{align}
    Using the properties listed in \Arf{eq:hermiteGaussProp} (mainly the
    recurrence) and the expansion \Arf{eq:omegaDef}. The incrementation of $j$
    follows the exact same derivation. The starting coefficient is thus
        \begin{equation}
            E^{00}_0 = K_{AB}
        \end{equation}
    This is found by inserting in $i=j=0$ into \Arf{eq:omegaIncr}, realizing
    the exponental is the same for all $i$ and $j$ and using the orthogonality
    between the Hermite-Gaussians\footnote{Another way of expressing this
    statement is to say that each index $t$ in the sum corresponds to an
    equation for $E^{ij}_t$.}. The recurrent coupled relations for the
    $E$'s are
        \begin{equation}
            \begin{aligned}
                E^{i+1,j}_t &= \frac{1}{2(\alpha + \beta)}E^{ij}_{t-1} -
                \frac{\beta}{\alpha+\beta}(A_x - B_x)E^{ij}_t +
                (t+1)E^{ij}_{t+1} \\
                E^{i,j+1}_t &= \frac{1}{2(\alpha + \beta)}E^{ij}_{t-1} -
                \frac{\alpha}{\alpha+\beta}(A_x - B_x)E^{ij}_t +
                (t+1)E^{ij}_{t+1}
            \end{aligned}
        \end{equation}
    The overlap distribution can with this be expanded in Hermite-Gaussian
    functions.

    As mentioned, the whole point of using Hermite-Gaussian functions is
    because of the inherent definition with the derivative with respect to the
    centering(remember s-types). This means that for attaining the final
    expression we must in the end differentiate the expansion coefficients. We
    state here the coefficients differentiated with respect to the difference
    variable $Q_x=A_x-B_x$
        \begin{equation}
            \begin{aligned}
                E^{00;n+1}_0 &=
                -\frac{2\alpha\beta}{\alpha+\beta}\left(Q_xE^{00;n}_0 +
                nE^{00;n-1}_0\right) \\
                E^{i+1,j;n}_t &= \frac{1}{2(\alpha+\beta)}E^{ij;n}_{t-1} -
                \frac{\beta}{\alpha+\beta}\left(Q_xE^{ij;n}_t +
                nE^{ij;n-1}_t\right) + (t+1)E^{ij;n}_{t+1} \\
                E^{i,j+1;n}_t &= \frac{1}{2(\alpha+\beta)}E^{ij;n}_{t-1} -
                \frac{\alpha}{\alpha+\beta}\left(Q_xE^{ij;n}_t +
                nE^{ij;n-1}_t\right) + (t+1)E^{ij;n}_{t+1} \\
                E^{ij;n}_t &\equiv \frac{\prtl^n E^{ij}_t}{\prtl Q^n_x}
            \end{aligned}
        \end{equation}
    Notice that these expressions are just the same relations as for the
    coefficients, but with an extra factor in the middle.

\subsection{Overlap Integral\label{susec:overlapIntegral}}
    With The simplification to s-types and the product rule, the integration
    may begin. Starting with the overlap $\Braket{i|j}$ and using
    \Arf{eq:omegaDef}\footnote{Also using the following integral $\infint
    \me^{-\lambda x^2} = \sqrt{\frac{\pi}{\lambda}},\indent \lambda>0$. See
    \cite{handbookmath}.}
        \begin{align}
            \Braket{i|j} &= \infint
            \Omega_{ij}(\alpha_p,\beta_p,\blds{r},\blds{A},\blds{B}) \md
            \blds{r} \nonumber \\
            &= \sumE{p}{i}{j} \infint g_p(\alpha,\beta,\blds{r},\blds{P})
            \md\blds{r} \nonumber \\
            &= \sumE{p}{i}{j} \infint (\blds{r}-\blds{P})^p \me^{-(\alpha_p +
            \beta_p)(\blds{r} - \blds{P})^2} \md\blds{r} \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^d
            \label{eq:stypeOverlap}
        \end{align}
    The power $d$ comes from splitting the integral into the $d$ dimensions.
    Also using the \txtit{multi-index
    notation}(\Arf{sec:multiIndexNotation})\footnote{The power $d$ also means
    that with the multi-index notation the entire expression in the paranthesis
    are to be calculated for each dimension in $p$ and then multiplied
    together.} and expanding
        \begin{equation}
            E^{ab}_{n} = \prod_d E^{a_db_d}_{n_d}
            \label{eq:Enotation}
        \end{equation}
    Such that the coefficients are all just products over coefficients in each
    dimension. A substitution in each dimension(i.e $u=x-P_x$) is also used.
    Notice in addition that the scaling factors $\alpha$ and $\beta$ are
    specific for each $p$ because of the overlap expansion.

\subsection{Potential Integral}
    The second integral with the $x^k_d$ part shows up in the external
    potential part of the Hamiltonian and again with the Gaussian product rule
    the expression gives
        \begin{align}
            \Braket{i|x^k_d|j} &= \infint x^{k}_d
            \Omega_{ij}(\alpha_p,\beta_p,\blds{r},\blds{A},\blds{B}) \md
            \blds{r} \nonumber \\
            &= \sumE{p}{i}{j} \infint x^k_d (\blds{r}-\blds{P})^p
            \me^{-(\alpha_p+\beta_p)(\blds{r} - \blds{P}_p)^2} \md \blds{r}
            \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^{D-1} \infint
            (u+P_d)^k\exp(-(\alpha_p+\beta_p)u^2) \md u \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^{D-1}
            \sum\limits_{l=0}^k {k\choose l} P^{k-l}_d \infint
            u^l\exp(-(\alpha_p+\beta_p)u^2) \md u \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^{D-1}
            \sum\limits_{l=0}^k {k\choose l}
            \frac{P^{k-l}_d}{2(\alpha_p+\beta_p)^{\frac{l}{2}}}
            \left((-1)^l+1\right) \Gamma\left(\frac{l+1}{2}\right)
            \label{eq:potIntegral}
        \end{align}
    The integrals are split in each dimension and the dimensions not equal to
    $d$(in $x^k_d$) are pulled out and the approach in \Arf{eq:stypeOverlap} is
    applied. The integral over dimension $d$ is then substituted with
    $u=x_d+P_d$. In line four $(u+P_d)^k$ is rewritten with the \txtit{binomial
    expansion}\footnote{The integral $\infint x^n\me^{-ax^2}\md x =
    \frac{1}{2}a^{-\frac{n}{2}}\Gamma\left(\frac{k+1}{2}\right),\indent n>-1,
    n\;\text{even}$, see \cite{handbookmath}.}.

\subsection{Laplacian Integral}
    The third integral with the Laplacian operator arises in the kinetic part
    of the Hamiltonian. This integral can be expressed in terms of
    \Arf{eq:stypeOverlap}, the overlap integral, however the Laplacian applied
    to a Hermite-Gaussian has to be calculated first
        \begin{align}
            \nabla^2 g_i(\alpha;\blds{r},\blds{A}) &= \sum_d \prd{x_d}[][2]
            \left(\prod_{d'} \left(x - A_{d'}\right)^{i_{d'}}_{d'} \exp(-\alpha
            \left(x_{d'} - A_{d'}\right)^2)\right)\nonumber \\
            &= \sum_d \prod_{d'\neq d} g_{i,d'} \prd{x_d}[][2]\left(\left(x_d -
            A_d\right)^{i_d} \exp(-\alpha \left(x_d - A_d\right)^2)\right)
            \nonumber \\
            &= \sum_d \prod_{d'\neq d} g_{i,d'} g_{i,d}
            \Bigg(4\alpha^2\left(x_d-A_d\right)^{i_d+2} -
            2\alpha\left(2i_d+1\right)\left(x_d-A_d\right)^{i_d} \nonumber \\ 
            &\hspace{3.5cm}+
            i_d\left(i_d-1\right)\left(x_d-A_d\right)^{i_d-2}\Bigg) \nonumber
            \\
            &= g_i\sum_d \Bigg(4\alpha^2\left(x_d-A_d\right)^{i_d+2} -
            2\alpha\left(2i_d+1\right)\left(x_d-A_d\right)^{i_d} \nonumber \\
            &\hspace{2.0cm}+
            i_d\left(i_d-1\right)\left(x_d-A_d\right)^{i_d-2}\Bigg)
        \end{align}
    Now for the integral we have
        \begin{align}
            \Braket{i|\nabla^2|j} &= \infint
            g_i(\alpha;\blds{r},\blds{A})\nabla^2g_j(\beta;\blds{r},\blds{B}) 
            \md\blds{r} \nonumber \\
            &= \sum_d\prod_{d'\neq d}
            \Braket{i_{d'}|\sigma_{d'}(S_d(\beta;x-B_d))|j_{d'}}
            \label{eq:laplacianIntegral}
        \end{align}
    with
        \begin{equation}
            \begin{aligned}
                S_d(\alpha;x_d-A_d) &\equiv
                \left(4\alpha^2\left(x_d-A_d\right)^{i_d+2} -
                2\alpha\left(2i_d+1\right)\left(x_d-A_d\right)^{i_d} +
                i_d\left(i_d-1\right)\left(x_d-A_d\right)^{i_d-2}\right) \\
                \sigma_d(S_d) &\equiv \left\{\begin{matrix}
                                            1,&\indent d' \neq d \\
                                            S_d,&\indent d' = d
                                            \end{matrix}
                                        \right.
            \end{aligned}
        \end{equation}
    meaning the Laplacian integral can be expressed in terms of the overlap
    integrals $\Braket{i|j+2}$, $\Braket{i|j}$ and
    $\Braket{i|i-2}$\footnote{Since $xg_i=g_{i+1}$ and
    $\frac{g_i}{x}=g_{i-1}$.}.

\subsection{Coulomb Potential Integral}
    Lastly, the troublesome\footnote{Damn inverse term prevents dimensional
    decomposition.} Coulomb integral needs to be calculated. Due to the $1/r$
    term we cannot split the integral in each respective dimension as
    previously. Before we approach the full Coulomb integral, lets calculate a
    simpler integral over a so-called \txtit{Coulomb Potential distribution}
        \begin{equation}
            \infint \me^{-\alpha\left(\blds{r} - \blds{A}\right)^2}
            \frac{1}{\abs{\blds{r} - \blds{B}}} \md\blds{r}
        \end{equation}
    The calculation of this integral will be beneficial for the calculation of
    the Coulomb integral as we can reuse most of the tricks used. With
    \Arf{eq:gaussianProductRule}, the Gaussian product rule, in mind. We
    rewrite the inverse term with
        \begin{equation}
            \infint \me^{r^2_B t^2} \md t = \frac{\sqrt{\pi}}{r_B} \Rarr
            \frac{1}{r_B} = \frac{1}{\sqrt{\pi}} \infint \me^{r^2_Bt^2} \md t
            \label{eq:onelectronTrick1}
        \end{equation}
    The Coulomb potential integral is thus, with
    \Arf{eq:gaussianProductRule}(again the product rule)
        \begin{align}
            \infint\infint \me^{-\alpha\left(\blds{r} - \blds{A}\right)^2}
            \frac{1}{\abs{\blds{r} - \blds{B}}} \md\blds{r} &=
            \frac{1}{\sqrt{\pi}}\infint \me^{-\alpha\left(\blds{r} -
            \blds{A}\right)^2} \me^{t^2(\blds{r} - \blds{B})^2} \md\blds{r} \md
            t \nonumber \\
            &= \frac{1}{\sqrt{\pi}} \infint\infint \me^{-\frac{\alpha
            t^2}{\alpha + t^2}\left(\blds{A} - \blds{B}\right)^2}
            \me^{-(\alpha+t^2)r^2_S} \md\blds{r} \md t \nonumber \\
            &= \frac{1}{\sqrt{\pi}} \infint \left(\frac{\pi}{\alpha +
            t^2}\right)^{\frac{d}{2}} \me^{-\frac{\alpha t^2}{\alpha +
            t^2}\left(\blds{A} - \blds{B}\right)^2} \md t
            \label{eq:coulombPotentialIntegral}
        \end{align}
    The integral over $t$ has to be addressed separately for two- and three
    dimensions. For the three-dimensional case the reader is referred to
    \cite{HelgakerTaylorGauss}. Here we will derive a closed-form form
    expression for the two-dimensional case. First let us use the following
    substitution
        \begin{equation}
            \begin{aligned}
                u &= \frac{t}{\sqrt{\alpha+t^2}} \\
                t &= u\sqrt{\frac{\alpha}{1-u^2}} \\
                \frac{\md u}{\md t} &= \frac{\alpha}{(\alpha +
                t^2)^{\frac{3}{2}}}
            \end{aligned}
            \hspace{2.5cm}
            \begin{aligned}
                \lim\limits_{t\rarr -\infty} u(t) &= -1 \\ 
                \lim\limits_{t\rarr \infty} u(t) &= 1
            \end{aligned}
            \label{eq:uSubs1}
        \end{equation}
    The integrand(ignoring the exponential part) is then
        \begin{align}
            \frac{\md t}{\alpha + t^2} &= \frac{1}{\alpha + t^2} \frac{(\alpha +
            t^2)^{\frac{3}{2}}}{\alpha} \md u \nonumber \\
            &= \frac{\sqrt{\alpha + t^2}}{\alpha} \md u \nonumber \\
            &= \frac{t}{\alpha u} \md u \nonumber \\
            &= \frac{1}{\alpha u} u\sqrt{\frac{\alpha}{1-u^2}} \md u \nonumber \\
            &= \frac{1}{\sqrt{\alpha}}\sqrt{\frac{1}{1-u^2}} \md u
        \end{align}
    giving
        \begin{align}
            I_{\text{2D}} = \sqrt{\frac{\pi}{\alpha}}\int\limits^1_{-1}
            \frac{1}{\sqrt{1-u^2}} \me^{-\alpha u^2\abs{\blds{A} - \blds{B}}^2}
            \md u
            \label{eq:oneElectron2D}
        \end{align}
    and for the three-dimensional case we have a simpler form(easily seen with
    the same substitution)
        \begin{align}
            I_{\text{3D}} = \pi\int\limits^1_{-1} \me^{-\alpha u^2\abs{\blds{A}
            - \blds{B}}^2} \md u
            \label{eq:oneElectron3D}
        \end{align}
    These integrals must be solved numerically using \txtit{Chebyshev-Gauss
    Quadrature}\cite{gausschebyshev}. One can also rewrite the 2D-integral in
    terms of the \txtit{Modified Bessel function of first kind} by using
    $u^2=1/2(1 - \cos(\theta)$\cite{modifiedBessel}.
    \cite{HelgakerTaylorGauss}. A take on this resulted nowhere as the closed
    form expanded itself in ever-increasing order of polynomial factors with
    the first and second order of the modified Bessel function of first kind.
    The 3D-integral can be rewritten with an \txtit{incomplete Gamma function}
    From \Arf{eq:centerDerGauss}, the integrals have to be differentiated in
    order to get the final closed form expressions, see \Arf{sub:445}.

\subsection{Coulomb Interaction Integral}
    In the previous section an expression for integral over a Coulomb potential
    was derived. Before we embark into handling the full Coulomb interaction
    integral, another exercise with simpler interaction integral is worthwhile.
    The integral in question is
        \begin{equation}
            I' = \infint\infint \me^{-\alpha(\blds{r'}-\blds{A})^2}
            \me^{-\beta(\blds{r}-\blds{B})^2} \frac{1}{\abs{\blds{r'} -
            \blds{r}}} \md\blds{r} \md\blds{r'}
            \label{eq:coulombInteractionSimple}
        \end{equation}
    This is an interaction between two distributions. Firstly, notice that we
    can rewrite the distribution centered in $\blds{A}$ and the Coulomb
    interaction with the previously calculated Coulomb potential integral given
    in \Arf{eq:coulombPotentialIntegral}. Using $I$ as a general label for
    \Arf{eq:oneElectron2D} and \Arf{eq:oneElectron3D} we have
        \begin{align}
            I' &= \infint\infint \me^{-\alpha(\blds{r'}-\blds{A})^2}
            \me^{-\beta(\blds{r}-\blds{B})^2} \frac{1}{\abs{\blds{r'} -
            \blds{r}}} \md\blds{r} \md\blds{r'} \nonumber \\
            &= \infint I_D(\alpha;\abs{\blds{r}-\blds{A}}) \me^{-\beta(\blds{r}
            - \blds{B})^2} \md\blds{r}
            \label{eq:Cintr1}
        \end{align}
    Inserting in the definition for $u$(the substitution in \Arf{eq:uSubs1})
    and using the extremely useful Gaussian product rule for the product
    between the distribution centered in $\blds{B}$ and the exponential factor
    in $I$(which is labelled the same for both the two- and three dimensional
    case) is
        \begin{equation}
            \me^{-\alpha u^2(\blds{r}-\blds{A})^2} \me^{-\beta(\blds{r} -
            \blds{B})^2} = \me^{-(\alpha u^2 + \beta)\blds{r_S}^2}
            \me^{-\frac{\alpha u^2\beta}{\alpha u^2 + \beta}
            (\blds{A}-\blds{B})^2}
        \end{equation}
    Inserting this into \Arf{eq:Cintr1} with
        \begin{equation}
            \upsilon \equiv \left\{
                \begin{matrix}
                    \sqrt{\frac{\pi}{\alpha}}\sqrt{\frac{1}{1-u^2}},&\indent
                    \text{2D} \\
                    \pi,&\indent \text{3D}
                \end{matrix}\right.
        \end{equation}
    we have
        \begin{align}
            I' &= \infint \int\limits^1_{-1} \upsilon \me^{-(\alpha u^2 +
            \beta)\blds{r_S}^2} \me^{-\frac{\alpha u^2\beta}{\alpha u^2 +
            \beta} (\blds{A}-\blds{B})^2} \md\blds{r}\md u \nonumber \\
            &= \int\limits^1_{-1} \upsilon \left(\frac{\pi}{\alpha u^2 +
            \beta}\right)^{\frac{d}{2}} \me^{-\frac{\alpha u^2\beta}{\alpha u^2
            + \beta}(\blds{A}-\blds{B})^2} \md u
        \end{align}
    Specializing to the two-dimensional case and substituting
        \begin{equation}
            \begin{aligned}
                v &= u\sqrt{\frac{\alpha+\beta}{\alpha u^2 + \beta}} \\
                \frac{\md v}{\md u} &= \frac{\beta\sqrt{\alpha+\beta}}{(\alpha
                u^2 + \beta)^{3/2}} \\
                u &= v \sqrt{\frac{\beta}{\alpha+\beta - \alpha v^2}} \\
                v(-1) &= -1 \\
                v(1) &= 1
            \end{aligned}
        \end{equation}
    The integrand is
        \begin{align}
            \frac{1}{\sqrt{1 - u^2}} \frac{1}{\alpha u^2 + \beta} \md u &=
            \frac{1}{\sqrt{1-u^2}} \frac{1}{\alpha u^2 + \beta} \frac{(\alpha
            u^2 + \beta)^{3/2}}{\beta\sqrt{\alpha+\beta}}\md v \nonumber \\
            &= \frac{1}{\sqrt{1-u^2}} \frac{u}{\beta v}\md v \nonumber \\
            &= \sqrt{\frac{\alpha+\beta -\alpha
            v^2}{(\alpha+\beta)(1-v^2)}}\frac{1}{\beta
            v}v\sqrt{\frac{\beta}{\alpha+\beta-\alpha v^2}} \md v \nonumber \\
            &= \frac{1}{\sqrt{\beta(\alpha+\beta)}} \frac{1}{\sqrt{1 - v^2}}
            \md v
        \end{align}
    we have
        \begin{equation}
            I'_{\text{2D}} =
            \frac{\pi^{\frac{3}{2}}}{\sqrt{\alpha\beta(\alpha+\beta)}}
            \int\limits^{1}_{-1} \frac{1}{\sqrt{1 - v^2}}
            \me^{-\frac{\alpha\beta}{(\alpha + \beta)}v^2(\blds{A}-\blds{B})^2}
            \md v
            \label{eq:coulombInteractionSimpleFinal}
        \end{equation}
    This expression will be of great use when calculating the final full
    interaction integral over the Coulomb distribution. The next section will
    derive the mentioned recurrence relation before the full Coulomb integral
    is calculated

\subsection{Recurrence Relation\label{sub:445}}
    Following directly from \cite{HelgakerTaylorGauss}, we proceed with finding
    a similar recurrence relation for the derivatives. We define a function
    containing the integral which needs to be solved numerically
        \begin{equation}
            \begin{aligned}
                \zeta_n(x) &\equiv \int\limits^1_{-1} \frac{u^{2n}}{\sqrt{1 -
                u^2}} \me^{-u^2x} \md u \\
                \prd{x}[\zeta_n] &= -\zeta_{n+1}
            \end{aligned}
            \label{eq:zetaDef}
        \end{equation}
    The Coulomb potential integral is then, in terms of $\zeta_n(x)$
        \begin{equation}
            \twoDI = \sqrt{\frac{\pi}{\alpha}} \zeta_0\left(\alpha
            R^2_{AB}\right)
        \end{equation}
    and the first derivative with respect to $A_x$ is
        \begin{align}
            \prd{A_x}[\twoDI] &= \sqrt{\frac{\pi}{\alpha}} \prd{A_x}
            \zeta_0\left(\alpha R^2_{AB}\right) \nonumber \\
            &= -2\sqrt{\alpha\pi}X_{AB}\zeta_1\left(\alpha R^2_{AB}\right)
        \end{align}
    With this we define an auxiliary function
        \begin{equation}
            \begin{aligned}
                \xi^n_{tu} &=\prdp{A_x}{t}\prdp{A_y}{u} \xi^n_{00} \\
                \xi^n_{00} &= (-2)^n\alpha^{n-\frac{1}{2}} \zeta_n\left(\alpha
                R^2_{AB}\right)
            \end{aligned}
            \label{eq:auxiliary2d1}
        \end{equation}
    and take a look at the incrementation of $t$
        \begin{align}
            \xi^n_{t+1,u} &= \prdp{A_x}{t}\prdp{A_y}{u} \prd{A_x}[\xi^n_{00}]
            \nonumber \\
            &= \prdp{A_x}{t}X_{AB}\xi^{n+1}_{0u}
            \label{eq:Rtincr}
        \end{align}
    Using the commutator between
    $\prtl^t_{A_x}$\footnote{$\prtl^t_x=\prd{x}[][t]$}
        \begin{align}
            \prd{A_x}[][t] X_{AB} &= \left[\prd{A_x}[][t], X_{AB}\right] +
            X_{AB}\prd{A_x}[][t] \nonumber \\
            &= t\prd{A_x}[][t-1] + X_{AB}\prd{A_x}[][t]
        \end{align}
    the final form of \Arf{eq:Rtincr} is\footnote{The incrementation of $u$ is
    derived in the exact same manner as with $t$.}
        \begin{equation}
            \begin{aligned}
                \xi^n_{t+1,u} &= t\xi^{n+1}_{t-1,u} + X_{AB}\xi^{n+1}_{t,u} \\
                \xi^n_{t,u+1} &= u\xi^{n+1}_{t,u-1} + Y_{AB}\xi^{n+1}_{t,u}
            \end{aligned}
        \end{equation}
    With this all Hermite integrals of order $t+u\leq N$ can be calculated from
    $\zeta$ of order $n\leq N$, the only difference being $X_{AB}$ and
    $Y_{AB}$. The Coulomb interaction integral
    (\Arf{eq:coulombInteractionSimpleFinal}) follows this exact recurrence, but
    with a different proportionality factor $\alpha\beta/(\alpha+\beta)$. We
    will write it out for the sake of clarity
        \begin{equation}
            \begin{aligned}
                \prd{A_x}[I'_{\text{2D}}] &= -\frac{2\alpha\beta}{\alpha+\beta}
                X_{AB}\zeta_1\left(\frac{\alpha\beta}{\alpha+\beta}R^2_{AB}\right)
                \\
                \xi^n_{00} &= \left(\frac{-2\alpha\beta}{\alpha+\beta}\right)^n
                \zeta_n\left(\frac{\alpha\beta}{\alpha+\beta} R^2_{AB}\right)
            \end{aligned}
            \label{eq:recurrInteraction}
        \end{equation}
    Notice that the only difference between the obtained recurrence relations
    and the ones obtained by Helgaker\cite{HelgakerGauss} is in
    \Arf{eq:auxiliary2d1} and \Arf{eq:recurrInteraction}. Other than this the
    incrementation of $\zeta_n$ gives the exact same $X_{AB}$(and similar for
    the other directions) as with the incomplete gamma function.

\subsection{Coulomb Distribution Integral}
    With the derived expressions for the Coulomb potential integral the full
    two-body distribution can be treated. The expression with the
    simplification in \Arf{eq:centerDerGauss} gives
        \begin{align}
            \Braket{ij|\frac{1}{r_{12}}|kl} &= \infint\infint
            \Omega_{ik}(\blds{\alpha},\blds{\gamma},\blds{r_1},
            \blds{A},\blds{C}) \frac{1}{\abs{\blds{r_1} - \blds{r_2}}}
            \Omega_{jl}(\blds{\beta},\blds{\delta},\blds{r_2},
            \blds{B},\blds{D}) \md\blds{r_1} \md\blds{r_2} \nonumber \\
            &= \suml{pq}{i+k,j+l} E^{ik}_pE^{jl}_q \infint\infint
            \frac{g_{p}(\alpha+\gamma,\blds{r_1},\blds{P})
            g_{q}(\beta+\delta,\blds{r_2},\blds{Q})}{\abs{\blds{r_1} -
            \blds{r_2}}} \md\blds{r_1} \md\blds{r_2}\nonumber \\
            &= \frac{a}{\sqrt{(\alpha+\gamma+\beta+\delta)}} \suml{pq}{i+k,j+l}
            E^{ik}_pE^{jl}_q (-1)^{q} \xi_{p+q}\left(\frac{(\alpha +
            \gamma)(\beta + \delta)}{\alpha + \gamma + \beta +
            \delta},\blds{R_{S_1S_2}}\right)
            \label{eq:coulomb_dist_integral_stype}
        \end{align}
    Where we have used the multi-index\footnote{Essentially just expanding an
    index in each dimension, for instance $i=(i_x,i_y,i_z)$ with corresponding
    $p=(p_x, p_y, p_z)$ with each index inside the tuple running to each
    respective index, meaning for instance $p_x=0$ to $i_x$ and so on.}
    notation for $p$, $q$, $i$, $k$, $j$, and $l$ \Arf{eq:Enotation}
    and used \Arf{eq:coulombInteractionSimpleFinal} to arrive at the final
    step. An additional simplification due to the fact that $\zeta_n$ is only
    dependant on the relative distance of the centers is also used, for the
    x-coordinate it is stated as
        \begin{equation}
            \prdp{P_x}{p_x}\prdp{Q_x}{q_x} = (-1)^{p_x+q_x} \prdp{P_x}{p_x+q_x}
        \end{equation}
    and the same for the other directions. The factor $a$ is
        \begin{equation}
            a \equiv \left\{\begin{aligned}
                \frac{\pi^{\frac{3}{2}}}
                {\sqrt{(\alpha+\gamma)(\beta+\delta)}},\indent \text{2D} \\
                \frac{\pi^{\frac{5}{2}}}
                {(\alpha+\gamma)(\beta+\delta)},\indent \text{3D} \\
            \end{aligned}\right.
        \end{equation}

\section{Double-Well Functions\label{sec:dwfunc}}
    This section will explain the building of a basis for the
    \txtit{double-well potential}. We will expand them in a linear combination
    of harmonicoscillator functions and find the coefficients of this expansion
    by solving the arising eigenvalue-problem. Let us first express the
    potential
        \begin{equation}
            \UDW(r) = \VHO(r) + \VDW_n(r)
            \label{eq:UDW}
        \end{equation}
    A double well potential is essentially just a perturbation of the usual
    Harmonicoscillator potential(which is a single-well). The $\VDW_n$ part is
    assumed to a polynomial of degree $n$. This means that the integral over
    such a potential can be calculated using \Arf{eq:potIntegral}.

\subsection{The Eigenvalue problem}
    The mentioned eigenvalue problem comes from the basis expansion of the
    spacial part and from the trick of projecting with a single function from
    left. We will explain briefly. First let us express the expansion,
        \begin{equation}
            \ket{\psiDW_p} = \sumll{l}C_{lp}\ket{\psiHO_l}
        \end{equation}
    and then project from left the bra $\bra{\psiHO_k}$ in the
    inner-product space of $h^{\text{DW}}$
        \begin{equation}
            \Braket{\psiHO_k|\hDW|\psiDW_p} =
            \sumll{l}C_{pl}\Braket{\psiHO_k|\hDW|\psiHO_l} =
            \sumll{l}C_{pl}\varepsilon^{\text{DW}}_l
        \end{equation}
    This gives us an eigenvalue equation
        \begin{equation}
            \blds{H}\blds{C} = \blds{\varepsilon^{\text{DW}}}\blds{C}
        \end{equation}
    with
        \begin{equation}
            H_{ij} = \Braket{\psiHO_i|h^{\text{DW}}|\psiHO_j}
        \end{equation}
    Using \Arf{eq:UDW} we can write $H_{ij}$ as
        \begin{equation}
            H_{ij} = \veps^{\text{HO}}_i\delta_{ij} +
            \Braket{\psiHO_i|\VDW_n|\psiHO_j}
            \label{eq:Heigdef}
        \end{equation}
    by using the solution to Schr√∂dinger's equation for the harmonic oscillator
    system. \\

    We are now in a position to build a basis for the double-well system by
    reusing all the results and expressions concerning the single-well system.
    The only difference is the extra integral over $\VDW_n$ where $n$ would be
    larger than $2$(as is the case with the harmonic oscillator potential). \\

    For clarity let us also write out the expression for the resulting
    Hartree-Fock basis to be used with the Variational Monte-Carlo method.
        \begin{equation}
            \psi^{\text{HF}}_p = \sumll{kl} C^{\text{HF}}_{pk}C_{kl}\psiHO_l
        \end{equation}

    The procedure of diagonalizing $H_{ij}$ also gives an additional set of
    energies we can use. The full form of the integral-elements involved in
    Hartree-Fock is thus
        \begin{equation}
            \begin{aligned}
                \Braket{\psiDW_p|\psiDW_q} &= \delta_{pq}
                \varepsilon^{\text{DW}}_p\delta_{pq} \\
                \Braket{\psiDW_p|h^{\text{DW}}|\psiDW_q} &=
                \varepsilon^{\text{DW}}_p\delta_{pq} \\
                \Braket{\psiDW_p\psiDW_q|\frac{1}{r_{12}}|\psiDW_r\psiDW_s} &=
                \suml{tuvw}{ijkl} C_{tp}C_{uq}C_{vr}C_{ws}
                \Braket{\psiHO_t\psiHO_u|\frac{1}{r_{12}}|\psiHO_v\psiHO_w}
            \end{aligned}
        \end{equation}
    Where the two-body elements over the harmonic oscillator functions can be
    calculated by expansion in s-type Gaussian constituents and then using
    \Arf{eq:coulomb_dist_integral_stype}. \\

    With this eigenvalue problem in mind, one might ask why go through the
    trouble? The reason lies in the form of the double-well potential. Since it
    is a simple shift of the single-well(harmonic oscillator) it is reasonable
    to assume that the energies(the eigenvalues $\veps^{\text{DW}}$) are only
    shifted slightly off from the single-well energies. It is then also
    reasonable to believe that a basis set expansion in the single-well
    functions(harmonic oscillator functions) give a nice basis for building the
    double-well basis.

\subsection{Choosing the Basis Functions}
    In order to actually solve the eigenvalue equation we use \text{Python} and
    the \text{NumPy} package, however we still need to choose the $\psiHO$'s
    first. This will be experimented with and we will choose enough to reach to
    \txtit{Hartree-Fock limit}. The choice will also follow the
    Harmonicoscillator levels in terms of degeneracy(see \Arf{subfig:3Dspin} and
    \Arf{subfig:2Dspin}). This means for instance that if we choose to only use $1$
    spacial function we only need the ground-state function, but there is no
    reason to believe that the electron-configuration would prefer any two(or
    $3$ in 3D) of the functions in the second level over one another. This
    means that we choose the basisfunctions according to the \txtit{magic
    numbers} of the Harmonicoscillator system basis.

\subsection{Degeneracy}
    When we tackled the single-well problem the energy-levels were degenerate
    and followed the magic numbers. For the double-well only the degeneracy due
    to spin is present. This means that we can(still with two-spin fermions)
    run the simulations with $N=2,4,6,\dots$ instead of the original
    $N=2,6,12,20,\dots$ in two dimensions and $N=2,8,20,30\dots$ in three.

\section{Summary\label{sec:basis_summary}}
    This chapter tackled the one- and two-body integrals over s-type Gaussian
    functions in two dimensions by using the results and approach of Trygve
    Helgaker. We will here rewrite the expressions found and write out the full
    expression for integrals over harmonic oscillator functions. \\

    Firstly the integrals over Hermite-Gaussians (monomials multiplied by
    exponential). The Hermite-Gaussian was expressed as 
        \begin{equation}
            g_n(\blds{\alpha};\blds{r},\blds{A}) = \prod_d
            \prdp{A_d}{n_d} \me^{-\alpha_d(x_d-A_d)^2}
            \label{eq:HGsumdef}
        \end{equation}
    An expansion of these in terms of Hermite-polynomials was then made to
    arrive at an overlap distribution, with the Gaussian product rule for the
    product of two Hermite-Gaussians, with a recursive relation for the
    expansion coefficients
        \begin{equation}
            \begin{aligned}
                \Omega_{ij}(\alpha,\beta,\blds{r},\blds{A},\blds{B}) &=
                \sum\limits^{i+j}_{t=0}
                E^{ij}_tg_t(\alpha,\beta,\blds{r},\blds{P}) \\
                E^{i+1,j}_t &= \frac{1}{2(\alpha + \beta)}E^{ij}_{t-1} -
                \frac{\beta}{\alpha+\beta}(A_x - B_x)E^{ij}_t +
                (t+1)E^{ij}_{t+1} \\
                E^{i,j+1}_t &= \frac{1}{2(\alpha + \beta)}E^{ij}_{t-1} -
                \frac{\alpha}{\alpha+\beta}(A_x - B_x)E^{ij}_t +
                (t+1)E^{ij}_{t+1} \\
                E^{00}_0 &= K_{AB} \\
            \end{aligned}
            \label{overlapdistdefsum}
        \end{equation}
    The overlap integral was then found to be
        \begin{equation}
            \Braket{g_i(\blds{\alpha};\blds{r},\blds{A}) |
            g_j(\blds{\beta};\blds{r},\blds{B})} = \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^d
            \label{eq:overlapintdefsum}
        \end{equation}
    The integral over a potential $x^k_d$ was found with the binomial expansion
    to be
        \begin{equation}
            \begin{aligned}
                \Braket{g_i(\blds{\alpha};\blds{r},\blds{A}) | x^k_d |
                g_j(\blds{\beta};\blds{r},\blds{B})} =&
                \suml{p=\text{even}}{i+j} E^{i+j}_p
                \left(\frac{\Gamma\left(\frac{p+1}{2}\right)}
                {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^{D-1} \bigtimes \\
                &\underset{\text{even}}{\sum\limits_{l=0}^k} {k\choose l}
                \frac{P^{k-l}_d}{2(\alpha_p+\beta_p)^{\frac{l}{2}}}
                \Gamma\left(\frac{l+1}{2}\right)
            \end{aligned}
        \end{equation}
    and the integral with the Laplacian was
        \begin{equation}
            \begin{aligned}
                \Bra{g_i(\blds{\alpha};\blds{r},\blds{A})} &\nabla^2
                \Ket{g_j(\blds{\beta};\blds{r},\blds{B})} = \\
                &\sum_d\prod_{d'\neq d}
                \Braket{g_{i_{d'}}(\alpha_{d'};x_{d'},A_{d'})
                |\sigma_{d'}(S_d(\beta;x_d-B_d))|g_{j_{d'}}(\beta_{d'};x_{d'},B_{d'})}
            \end{aligned}
            \label{eq:lapintdefsum}
        \end{equation}
    with
        \begin{equation}
            \begin{aligned}
                S_d(\alpha;x_d-A_d) &\equiv
                \left(4\alpha^2\left(x_d-A_d\right)^{i_d+2} -
                2\alpha\left(2i_d+1\right)\left(x_d-A_d\right)^{i_d} +
                i_d\left(i_d-1\right)\left(x_d-A_d\right)^{i_d-2}\right) \\
                \sigma_d(S_d) &\equiv \left\{\begin{matrix}
                                            1,&\indent d' \neq d \\
                                            S_d,&\indent d' = d
                                            \end{matrix}
                                        \right.
            \end{aligned}
        \end{equation}
    Finally the integral over the Coulomb interactions was calculated using a
    recursive relation for the one-dimensional integral it was defined by. The
    expressions are
        \begin{equation}
            \Braket{g^{\blds{\alpha}}_{iA}g^{\blds{\beta}}_{jB} |
            \frac{1}{r_{12}} | g^{\blds{\delta}}_{kC}g^{\blds{\gamma}}_{lD}} =
            \frac{a}{\sqrt{(\alpha+\gamma+\beta+\delta)}} \suml{pq}{i+k,j+l}
            E^{ik}_pE^{jl}_q (\scalebox{1.0}[1.0]{-}1)^{q} \xi_{p+q}\left(\frac{(\alpha +
            \gamma)(\beta + \delta)}{\alpha + \gamma + \beta +
            \delta},\blds{R_{S_1S_2}}\right)
            \label{eq:coulombdistintdefsum}
        \end{equation}
    with
        \begin{equation}
            a \equiv \left\{\begin{aligned}
                \frac{\pi^{\frac{3}{2}}}
                {\sqrt{(\alpha+\gamma)(\beta+\delta)}},\indent \text{2D} \\
                \frac{\pi^{\frac{5}{2}}}
                {(\alpha+\gamma)(\beta+\delta)},\indent \text{3D} \\
            \end{aligned}\right.
        \end{equation}
    And the recursive relation in two dimensions(left) and three dimensions
    (right)
        \begin{equation}
            \begin{aligned}
                \xi^n_{t+1,u} &= t\xi^{n+1}_{t-1,u} + X_{AB}\xi^{n+1}_{t,u} \\
                \xi^n_{t,u+1} &= u\xi^{n+1}_{t,u-1} + Y_{AB}\xi^{n+1}_{t,u} \\
                \xi^n_{00} &= \left(\frac{-2\alpha\beta}{\alpha+\beta}\right)^n
                \zeta_n\left(\frac{\alpha\beta}{\alpha+\beta} R^2_{AB}\right) \\
                \zeta_n(x) &= \int\limits^1_{-1} \frac{u^{2n}}{\sqrt{1 -
                u^2}} \me^{-u^2x} \md u
            \end{aligned} \indent\indent\indent 
            \begin{aligned}
                \xi^n_{t+1,u,v} &= t\xi^{n+1}_{t-1,u,v} + X_{AB}\xi^{n+1}_{t,u,v} \\
                \xi^n_{t,u+1,v} &= u\xi^{n+1}_{t,u-1,v} + Y_{AB}\xi^{n+1}_{t,u,v} \\
                \xi^n_{t,u,v+1} &= u\xi^{n+1}_{t,u,v-1} + Y_{AB}\xi^{n+1}_{t,u,v} \\
                \xi^n_{000} &= \left(-2\alpha\beta\right)^n
                \zeta_n\left(\frac{\alpha\beta}{\alpha+\beta} R^2_{AB}\right)
                \\
                \zeta_n(x) &= \int\limits^1_{-1} u^{2n} \me^{-u^2x} \md u
            \end{aligned}
        \end{equation}

    We also give a reminder again that these expressions are only valid for
    \txtit{isotropic} Gaussian functions, Gaussians whose scaling factor(i.e
    $\alpha$) is the same in all dimensions. For the non-isotropic case the see
    \cite{nonIsoGauss}. \\

    And as promised, here are the full expressions for the integral elements with
    harmonic oscillator functions using \Arf{eq:coulombdistintdefsum} and the
    orthogonality of the harmonic oscillator functions
        \begin{equation}
            \Braket{\psiHO_i|\psiHO_j} = N_i \delta_{ij}
            \label{eq:HOoverlap}
        \end{equation}
        \begin{equation}
            \Braket{\psiHO_i|h^{\text{HO}}|\psiHO_j} = N_i
            \varepsilon^{\text{HO}}_i\delta_{ij}
        \end{equation}
        \begin{equation}
            \Braket{\psiHO_i\psiHO_j|\frac{1}{r_{12}}|\psiHO_k\psiHO_l} =
            N_{ijkl}\frac{a}{\sqrt{2\omega}}  \sum^{ijkl}_{tuvw}
            H^{ijkl}_{tuvw} \suml{pq}{t+v,u+w} E^{tv}_pE^{uw}_q
            (-1)^q\xi_{p+q}\left(\frac{\omega}{2}, \blds{0}\right)
        \end{equation}
        \begin{equation}
            a \equiv \left\{\begin{aligned}
                \frac{\pi^{\frac{3}{2}}} {\sqrt{\omega}},\indent \text{2D} \\
                \frac{\pi^{\frac{5}{2}}} {\omega},\indent \text{3D} \\
            \end{aligned}\right.
        \end{equation}
    with the notations
        \begin{equation}
            \begin{aligned}
                N_{ijkl} &= X_i X_j X_k X_l \\
                \suml{tuvw}{ijkl} &=
                \suml{p}{t}\suml{q}{u}\suml{r}{v}\suml{s}{w} \\
                \suml{pq}{t+v,u+w} &= \suml{p}{t+v}\suml{q}{u+w} \\
                H^{ijkl}_{tuvw} &= H_{i,t} H_{j,u} H_{k,v} H_{l,w} \\
                E^{tv}_p &= E_{p,t+v}
            \end{aligned}
        \end{equation}
    And using the multi-index notation for the dimensions in $p$ and $q$
    indices. The $H$ are the Hermite coefficients.

\section{Further Work}
    This concludes this chapter on basis functions. We have found an expression
    for the integral elements involving Hermite-Gaussians and used these to
    express the integral over harmonic oscillator functions which in turn gave
    an expression for the integrals over double-well functions as they were
    just expanded in harmonic oscillator functions. The next chapter will
    present optimizations methods used in the variational method and the
    implementations of these integrals are presented in \Arf{chapter:6}. \\

    As a note for further work the expressions found here are for isotropic
    gaussians only. For certain systems, like the one presented in
    article\cite{nonIsoGauss}, more flexibility in the Gaussian functions can
    be desired, such that finding expression for the integrals of Gaussian
    functions with higher order monomial factors and extending the existing
    code to calculate those can be of desire.
