%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapter 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{\label{chapter:4}}
    We will in this chapter mentiond some popular basis-sets used in atomic
    physics and deepen into a particular set of functions called
    \txtit{Gaussian Type orbitals} and mimic the well known \txtit{Hermite
    polynomials}.

\section{Hermite Functions}
    Hermite functions are functions of the following form
        \begin{equation}
            \phi^a_n(\blds{r}) \equiv \prod_d N_d
            H_{n_d}(\sqrt{a}x_d)\exp(-\frac{a}{2}x^2_d)
            \label{eq:HermiteFunc}
        \end{equation}
    with $\blds{r} = \sum\limits_d \blds{\me}_dx_d$ and the sum over $d$ being
    the sum over the number of dimensions and the $H_n$ is the Hermite
    polynomial of order $n$. The integer $n_d$ is the order of the
    function\footnote{In quantum mechanics the number $n$ is referred to as the
    principal quantum number and is associated with the energy of a given
    orbital(energy-level) of the system.} while the parameter $a$ is a scaling
    factor and $N_d$ is a normalization factor. These functions show up as
    eigenfunctions for the \txtit{quantum harmonic oscillator
    system}\cite{GriffQuan} with the scaling parameter $a$ equal to the
    oscillator frequency ($\omega$) of the system.

    The Hermite functions are orthogonal and give a good ansatz for the VMC
    method, see \Arf{sec:QMC}, with the scaling parameter transformed with an
    additional variational parameter. The problem with these are however that
    the matrix-elements introduced in the Hartree-Fock method
    (\Arf{sec:HFtheory}) are not solveable with the Hermite functions as basis
    functions. >> REF FURTHER DISCUSSION <<

\section{Gaussian Type Orbitals}
    \txtit{Gaussian Type Orbitals} or GTO's are functions of the following form
    >> REF GTO here <<
        \begin{equation}
            G_n(\blds{\alpha};\blds{r},\blds{A}) \equiv \prod_d (x_d-A_d)^{n_d}
            \me^{-\alpha_d (x_d-A_d)^2}
            \label{eq:GTOdef1d}
        \end{equation}
    We call $\alpha$ for the scaling parameter and $i$ for the order of the
    GTO. The variable $A$ is where the function is centered. These are in many
    literatures referred to as \txtit{primitive Gaussians} and they alone
    make a poor approximation to the true wave function.

    In atomic physics these functions are used directly as a linear combination
    referred to as \txtit{contracted Gaussian functions}. These are written as
        \begin{equation}
            G_k(x, A) \equiv \sum\limits^P_{a_k=0} C_{a_k}
            G_{a_k}(\alpha_{a_k};x, A)
        \end{equation}
    and are fitted\footnote{Meaning we find the parameters $C_{a_k}.$ and
    $\alpha_{a_k}$} to \txtit{Slater-type orbitals}, which are functions with
    decaying properties(present in atomic systems), or found by some variational
    method before-hand. \\

    These functions are unfortunately not orthogonal, but they behave nicely in
    integrals and actually give an analytic expression for the
    interaction-elements mentioned in \Arf{sec:HFtheory}. For this reason we
    will go forth and use the Gaussian contracted functions and actually fit
    them to Hermite functions.

\section{Fitting GTO's to Hermite Functions with Least-Squares}
    Looking at \Arf{eq:HermiteFunc, eq:GTOdef1d} we see that both functions are
    separable in the different dimensions. For this reason we simplify to only
    work in one dimensions with label $x$ for the positions and omit the
    subscript $d$. We will also specialize to the quantum dot case where the
    imagined nuclei is centered in origo for all orbitals. The functions will
    hereby be written as
        \begin{equation}
            \begin{aligned}
                \phi_n(x) &= NH_n(\sqrt{\omega}x)\me^{-\frac{\omega}{2}x^2} \\
                G_n(x, A) &= \sum\limits^{n+1}_{b_n=0} C_{b_n}
                G_{b_n}(\alpha;x, A)
            \end{aligned}
        \end{equation}
    First observation here is that we choose the scaling parameter in the GTO
    to be equal to the oscillator frequency $\omega$ halved. We then only have
    $1$ set of coefficients to determine, namely the $\{C\}^P_{a_k}$. Note also
    that the sum in the contracted function runs to $n+1$, we will show later
    that this is sufficient to approximate the Hermite of order $n$.

    A Least-Squares problem for a continuous set $x\in\mathbb{R}$ is defined to
    be of form
        \begin{equation}
            \min_{\{a\}} \abs{\int (f(x) - \sum_ja_jg_j(x)) \md x}^2 \indent
            \forall \;\;x\in\mathbb{R}
        \end{equation}
    where we minimize with respect to a set of parameters $\{a\}$. The
    stationary point in the parameters space of the $a$'s is reached when all
    partial derivatives of $\{a\}$ is zero. This can be expressed as a linear system
        \begin{equation}
            \blds{X} \blds{a} = \blds{b}
        \end{equation}
    with the matrix $\blds{X}$ having elements
        \begin{equation}
            X_{ij} \equiv \int g_i(x)g_j(x) \md x
        \end{equation}
    and the vector $\blds{b}$
        \begin{equation}
            b_i \equiv \int g_i(x)f(x) \md x
        \end{equation}
    Inserting the Hermite function for $f$ and the GTO for $g$ the integrands
    (see \Arf{appendix:B}) we get
        \begin{equation}
            \begin{aligned}
                X_{ij} &= \int x^i N_i N_j \me^{\frac{\omega}{2} x^2} x^j
                \me^{\frac{\omega}{2} x^2} \md x \\
                b_i &= \int N_i x^i \me^{\frac{\omega}{2} x^2}
                \left(2^nn!\sqrt{\frac{\pi}{\omega}}\right)^{-\frac{1}{2}}
                H_n(\sqrt{\omega}x) \me^{\frac{\omega}{2} x^2} \md x
            \end{aligned}
        \end{equation}
    We can solve this by hand, but it is desirable to solve it using Sympy. See
    >>REF IMPLEMENTATION CHAPTER <<.

\section{Integral Elements}
    In the Hartree-Fock scheme described in \Arf{chapter:3} we need to
    calculate the integrals which define the different matrix elements. The
    integrals to be found are of the following form
        \begin{equation}
            \begin{aligned}
                \braket{i}{j} &= \infint g_i(\alpha_i;r,A)g_j(\alpha_j;r,B) \md
                \blds{r} \\
                \bra{i}r^k\ket{j} &= \infint g_i(\alpha_i;r,A) r^k
                g_j(\alpha_j;r,B) \md \blds{r} \\
                \bra{i}\nabla^2\ket{j} &= \infint g_i(\alpha_i;r,A)\nabla^2
                g_j(\alpha_j;r,B) \md \blds{r} \\
                \bra{ij}r^{-1}\ket{kl} &= \infint
                g_i(\alpha_i;r_1,A)g_j(\alpha_j;r_2,B) \frac{1}{r_{12}}
                g_k(\alpha_k;r_1,C)g_l(\alpha_l;r_2,D) \md \blds{r}_1 \md
                \blds{r}_2\\
            \end{aligned}
        \end{equation}
    where $\md\blds{r}$ means integration over all dimensions and with the
    $g$'s being the usual \txtit{Hermite-Gaussians} defined as
        \begin{equation}
            g_n(\alpha;\blds{r},\blds{A}) = \prod_d \alpha^{n_d}(x_d-A_d)^{n_d}
            \me^{-\alpha (x_d-A_d)^2}
        \end{equation}
    We will in this chapter limit ourselves to work with isotropic gaussians
    (meaning $\alpha_d$ is the same for all dimensions) as this will yield a
    simpler closed-form solution to the integrals. >> Ref non-isotropic <<. \\
    The approach given further follows closely the excellent text by Helgaker
    >>REF<<, who calculates the integral elements in 3 dimensions.

    Before we throw ourselves out into the integrals, let us first express the
    Hermite-Gaussians in a more convenient way >> REF HELGAKER <<. The
    Gaussians can be expressed as
        \begin{equation}
            g_n(\alpha;\blds{r},\blds{A}) = \prod_d  \prdp{A_{x_d}}{n_d}
            \me^{-\alpha (x_d-A_d)^2} = \prod_d  \prdp{A_{x_d}}{n_d}
            g_0(\alpha;\blds{r},\blds{A})
        \end{equation}
    Since the derivatives are with respect to the center variables we may pull
    them out of the integration meaning the integrals will only be over s-type
    Gaussians, greatly simplifying the calculations. With the mentioned
    simplification in mind, the problem is to find a closed-form expression for
    the integrals over s-type Gaussians. We proceed with the overlap element first.

    Since we only work with s-types when integrating we introduce a new notation
        \begin{equation}
            \begin{aligned}
                \bra{A}\hat{O}\ket{B} &\equiv \int g_0(\alpha,\blds{r},\blds{A})
                \hat{O} g_0(\beta,\blds{r},\blds{B}) \md\blds{r}\\
                \bra{AB}\hat{O}\ket{CD} &\equiv \int
                g_0(\alpha,\blds{r_1},\blds{A})g_0(\beta,\blds{r_2},\blds{B})
                \hat{O} g_0(\gamma,\blds{r_1},\blds{C})
                g_0(\delta,\blds{r_2},\blds{D}) \md\blds{r_1} \md\blds{r_2}\\
            \end{aligned}
        \end{equation}

    We also introduce the \txtit{Gaussian product rule}\footnote{Still in the
    isotropic case.} which basically states that the product of two Gaussian
    functions is just a third Gaussian centered between the center of the two.
    The expressions give
        \begin{equation}
                g_0(\alpha;\blds{r},\blds{A})g_0(\beta;\blds{r},\blds{B}) =
                K_{AB}\exp(-(\alpha+\beta)\blds{r}^2_s)
        \end{equation}
    where
        \begin{equation}
            \begin{aligned}
                K_{AB} &\equiv \exp(-\frac{\alpha\beta}{\alpha+\beta}R^2_{AB})
                \\
                R_{AB} &= \abs{\blds{A} - \blds{B}} \\
            \end{aligned}
        \end{equation}
    the vector $\blds{r}_S$ is just somewhere between $\blds{A}$ and
    $\blds{B}$\footnote{We will see that $r_S$ disappears when the integration
    is done.}.

    With The simplification to s-types and the product rule we can start with
    calculating the integrals. We start with the overlap $\braket{A}{B}$
