%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Chapter 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Basis Functions\label{chapter:4}}
    We will in this chapter mention some popular basis-sets used in atomic
    physics and deepen into a particular set of functions called
    \txtit{Gaussian Type orbitals} and use them with the well known
    \txtit{Hermite functions}.

\section{Hermite Functions}
    Hermite functions are functions of the following form
        \begin{equation}
            \phi^a_n(\blds{r}) \equiv \prod_d N_d
            H_{n_d}(\sqrt{a}x_d)\exp(-\frac{a}{2}x^2_d)
            \label{eq:HermiteFunc}
        \end{equation}
    with $\blds{r} = \sum\limits_d \blds{\me}_dx_d$ and the sum over $d$ being
    the sum over the number of dimensions and the $H_n$ is the Hermite
    polynomial of order $n$. The integer $n_d$ is the order of the
    function\footnote{In quantum mechanics the number $n$ is referred to as the
    principal quantum number and is associated with the energy of a given
    orbital(energy-level) of the system.} while the parameter $a$ is a scaling
    factor and $N_d$ is a normalization factor. These functions show up as
    eigenfunctions for the \txtit{quantum harmonic oscillator
    system}\cite{GriffQuan} with the scaling parameter $a$ equal to the
    oscillator frequency ($\omega$) of the system.

    The Hermite functions are orthogonal and give a good ansatz for the VMC
    method, see \Arf{sec:QMC}, with the scaling parameter transformed with an
    additional variational parameter. The problem with these are however that
    the matrix-elements introduced in the Hartree-Fock method
    (\Arf{sec:HFtheory}) are not solvable directly with the Hermite functions
    as basis functions. However, we can write the Hermite functions in terms of
    \txtit{Hermite-Gaussians}. See \Arf{sec:hermiteGaussFunc}.

\section{Gaussian Type Orbitals}
    \txtit{Gaussian Type Orbitals} or GTO's are functions of the following form
    >> REF GTO here <<
        \begin{equation}
            G_n(\blds{\alpha};\blds{r},\blds{A}) \equiv \prod_d (x_d-A_d)^{n_d}
            \me^{-\alpha_d (x_d-A_d)^2}
            \label{eq:GTOdef1d}
        \end{equation}
    We call $\alpha$ for the scaling parameter and $i$ for the order of the
    GTO. The variable $A$ is where the function is centered. These are in many
    literatures referred to as \txtit{primitive Gaussians} and they alone
    make a poor approximation to the true wave function.

    In atomic physics these functions are used directly as a linear combination
    referred to as \txtit{contracted Gaussian functions}. These are written as
        \begin{equation}
            G_k(x, A) \equiv \sum\limits^P_{a_k=0} C_{a_k}
            G_{a_k}(\alpha_{a_k};x, A)
        \end{equation}
    and are fitted\footnote{Meaning we find the parameters $C_{a_k}.$ and
    $\alpha_{a_k}$} to \txtit{Slater-type orbitals}, which are functions with
    decaying properties(present in atomic systems), or found by some variational
    method before-hand. \\

    These functions are unfortunately not orthogonal, but they behave nicely in
    integrals and actually give an analytic expression for the
    interaction-elements mentioned in \Arf{sec:HFtheory}. For this reason we
    will go forth and use the Gaussian contracted functions and actually fit
    them to Hermite functions.

\subsection{Hermite-Gaussian Functions\label{sec:hermiteGaussFunc}}
    The GTO's described can be explicitly expressed in terms of so-called
    \txtit{Hermite-Gaussian functions}\footnote{The reason for the name is that
    the polynomial factors generated by the differentiation are precisely the
    Hermite polynomials.} defined as
        \begin{equation}
            g_n(\blds{\alpha};\blds{r},\blds{A}) = \prod_d
            \prdp{A_d}{n_d} \me^{-\alpha_d(x_d-A_d)^2}
        \end{equation}
    meaning
        \begin{equation}
            G_n(\blds{\alpha;\blds{r},\blds{A}}) = \prod_d
            (2\alpha_d)^{-n_d}\prdp{A_d}{n_d} \me^{-\alpha_d(x_d-A_d)^2}
        \end{equation}
    Some properties of the one-dimensional Hermite-Gaussians are as follows
        \begin{equation}
            \begin{aligned}
                \prd{A_x}[g_t] &= g_{t+1} \\
                g_{t+1} &= \prdp{A_x}{t}\prd{A_x}[g_0] =
                2\alpha(x-A_x)\prdp{A_x}{t}g_0 \\
                g_{t+1} &= 2\alpha((x-A_x)g_t - tg_{t-1}) \\
                (x-A_x)g_t &= \frac{1}{2\alpha}g_{t+1} + tg_{t-1}
            \end{aligned}
            \label{eq:hermiteGaussProp}
        \end{equation}
    The mentioned rewriting of the Hermite functions in terms of the
    Hermite-Gaussians is
        \begin{equation}
            \phi^a_n(\blds{r}) = \prod_d N_d \sum\limits^{n_d}_{l=0} C_{n_dl}
            g_l\left(\frac{\blds{\alpha}}{2},\blds{r},\blds{A}\right)
        \end{equation}
    with $C_{n_dl}$ being the $l'th$ Hermite-coefficient for the Hermite
    polynomial of order $n_d$. This means that the matrix-elements in
    Hartree-Fock is just a linear combination over integrals over
    Hermite-Gaussians. The following section will tackle this in detail for the
    two-dimensional case. The three-dimensional is given by >> REF HELGAKER <<.

% \section{Fitting GTO's to Hermite Functions with Least-Squares}
%     Looking at \Arf{eq:HermiteFunc, eq:GTOdef1d} we see that both functions are
%     separable in the different dimensions. For this reason we simplify to only
%     work in one dimensions with label $x$ for the positions and omit the
%     subscript $d$. We will also specialize to the quantum dot case where the
%     imagined nuclei is centered in origo for all orbitals. The functions will
%     hereby be written as
%         \begin{equation}
%             \begin{aligned}
%                 \phi_n(x) &= NH_n(\sqrt{\omega}x)\me^{-\frac{\omega}{2}x^2} \\
%                 G_n(x, A) &= \sum\limits^{n+1}_{b_n=0} C_{b_n}
%                 G_{b_n}(\alpha;x, A)
%             \end{aligned}
%         \end{equation}
%     First observation here is that we choose the scaling parameter in the GTO
%     to be equal to the oscillator frequency $\omega$ halved. We then only have
%     $1$ set of coefficients to determine, namely the $\{C\}^P_{a_k}$. Note also
%     that the sum in the contracted function runs to $n+1$, we will show later
%     that this is sufficient to approximate the Hermite of order $n$.
% 
%     A Least-Squares problem for a continuous set $x\in\mathbb{R}$ is defined to
%     be of form
%         \begin{equation}
%             \min_{\{a\}} \abs{\int (f(x) - \sum_ja_jg_j(x)) \md x}^2 \indent
%             \forall \;\;x\in\mathbb{R}
%         \end{equation}
%     where we minimize with respect to a set of parameters $\{a\}$. The
%     stationary point in the parameters space of the $a$'s is reached when all
%     partial derivatives of $\{a\}$ is zero. This can be expressed as a linear system
%         \begin{equation}
%             \blds{X} \blds{a} = \blds{b}
%         \end{equation}
%     with the matrix $\blds{X}$ having elements
%         \begin{equation}
%             X_{ij} \equiv \int g_i(x)g_j(x) \md x
%         \end{equation}
%     and the vector $\blds{b}$
%         \begin{equation}
%             b_i \equiv \int g_i(x)f(x) \md x
%         \end{equation}
%     Inserting the Hermite function for $f$ and the GTO for $g$ the integrands
%     (see \Arf{appendix:B}) we get
%         \begin{equation}
%             \begin{aligned}
%                 X_{ij} &= \int x^i N_i N_j \me^{\frac{\omega}{2} x^2} x^j
%                 \me^{\frac{\omega}{2} x^2} \md x \\
%                 b_i &= \int N_i x^i \me^{\frac{\omega}{2} x^2}
%                 \left(2^nn!\sqrt{\frac{\pi}{\omega}}\right)^{-\frac{1}{2}}
%                 H_n(\sqrt{\omega}x) \me^{\frac{\omega}{2} x^2} \md x
%             \end{aligned}
%         \end{equation}
%     We can solve this by hand, but it is desirable to solve it using Sympy. See
%     >>REF IMPLEMENTATION CHAPTER <<.

\section{Integral Elements}
    In the Hartree-Fock scheme described in \Arf{chapter:3} we need to
    calculate the integrals which define the different matrix elements. The
    integrals to be found are of the following form
        \begin{equation}
            \begin{aligned}
                \Braket{i|j} &= \infint g_i(\alpha_i;r,A)g_j(\alpha_j;r,B) \md
                \blds{r} \\
                \Braket{i|x^k_d|j} &= \infint g_i(\alpha_i;r,A) r^k
                g_j(\alpha_j;r,B) \md \blds{r} \\
                \Braket{i|\nabla^2|j} &= \infint g_i(\alpha_i;r,A)\nabla^2
                g_j(\alpha_j;r,B) \md \blds{r} \\
                \Braket{ij|\frac{1}{r}|kl} &= \infint\infint
                g_i(\alpha_i;r_1,A)g_j(\alpha_j;r_2,B) \frac{1}{r_{12}}
                g_k(\alpha_k;r_1,C)g_l(\alpha_l;r_2,D) \md \blds{r}_1 \md
                \blds{r}_2\\
            \end{aligned}
        \end{equation}
    where $\md\blds{r}$ means integration over all dimensions and with the
    $g$'s being the usual \txtit{Hermite-Gaussians} defined as
        \begin{equation}
            g_n(\alpha;\blds{r},\blds{A}) = \prod_d (x_d-A_d)^{n_d}
            \me^{-\alpha (x_d-A_d)^2}
            \label{eq:hermiteGauss2}
        \end{equation}
    We will in this chapter limit ourselves to work with isotropic gaussians
    (meaning $\alpha_d$ is the same for all dimensions) as this will yield a
    simpler closed-form solution to the integrals. >> Ref non-isotropic <<. \\
    The approach given further follows closely the excellent text by Helgaker
    >>REF<<, who calculates the integral elements in 3 dimensions.

    Before we throw ourselves out into the integrals, let us first express the
    Hermite-Gaussians in a more convenient way >> REF HELGAKER <<. The
    Gaussians can be expressed as
        \begin{equation}
            g_n(\alpha;\blds{r},\blds{A}) = \prod_d  \prdp{A_{x_d}}{n_d}
            \me^{-\alpha (x_d-A_d)^2} = \prod_d \prdp{A_{x_d}}{n_d}
            g_0(\alpha;\blds{r},\blds{A})
            \label{eq:centerDerGauss}
        \end{equation}
    Since the derivatives are with respect to the center variables we may pull
    them out of the integration meaning the integrals will only be over s-type
    Gaussians, greatly simplifying the calculations. With the mentioned
    simplification in mind, the problem is to find a closed-form expression for
    the integrals over s-type Gaussians.

    We also introduce the \txtit{Gaussian product rule}\footnote{Still in the
    isotropic case.} which basically states that the product of two Gaussian
    functions is just a third Gaussian centered between the center of the two.
    The expressions give
        \begin{equation}
            g_0(\alpha;\blds{r},\blds{A})g_0(\beta;\blds{r},\blds{B}) =
            K_{AB}\exp(-(\alpha+\beta)\blds{r}^2_s)
            \label{eq:gaussianProductRule}
        \end{equation}
    where
        \begin{equation}
            \begin{aligned}
                K_{AB} &\equiv \exp(-\frac{\alpha\beta}{\alpha+\beta}R^2_{AB})
                \\
                R_{AB} &= \abs{\blds{A} - \blds{B}} \\
                \blds{r_s} &= \blds{r} - \blds{P} \\
                \blds{P} &= \frac{\alpha\blds{A} +
                \beta\blds{B}}{\alpha + \beta}
            \end{aligned}
        \end{equation}
    the vector $\blds{r}_S$ is just somewhere between $\blds{A}$ and
    $\blds{B}$(We will see that $r_S$ disappears when the integration is done).
    The Gaussian product rule greatly simplifies the integral over two Gaussian
    functions since we can just pull $K_{AB}$ out of the integration since it
    is a constant.

\subsection{Overlap Distribution}
    An \txtit{overlap distribution} is defined >>REF THIS<< as the product
    between two Hermite-Gaussian functions, that is
        \begin{equation}
            \Omega_{ij} = \prod_d g_{i_d}(x_d,\alpha,A_d)g_{j_d}(x_d,\beta,B_d)
            =
            K_{A_dB_d}x_A^{i_d}x_B^{j_d}\me^{-(\alpha+\beta)x^2_P}
        \end{equation}
    with the Gaussian product rule, which is just another Gaussian function
    centered in $P$, but with the extra \txtit{monomial} factors in
    $\blds{r}-\blds{A}$ and $\blds{r}-\blds{B}$. These factors are troublesome
    when integrating. With the motivation that Hermite-Gaussians make life
    simpler, we expand the overlap distribution in a Hermite-Gaussian basis.
    Following >>REF HELGAKER<< and working in one dimension(since
    Hermite-Gaussians can be split in each respective dimension) we
    have\footnote{The indices $i$ and $j$ are now in 1 dimension!}
        \begin{equation}
            \Omega_{ij}(\alpha,\beta,\blds{r},\blds{A},\blds{B}) =
            \sum\limits^{i+j}_{t=0} E^{ij}_tg_t(\alpha,\beta,\blds{r},\blds{P})
            \label{eq:omegaDef}
        \end{equation}
    Again, we stress that the indices in \Arf{eq:omegaDef} and the calculations
    further are in 1 dimension. Explicit expressions for the coefficients
    $E^{ij}_t$ are difficult to derive, however a set of recurrence relations
    are possible to find using the properties of the Hermite-Gaussian
    functions. Consider firstly the incremented distribution
        \begin{align}
            \Omega_{i+1,j} &= \sum^{i+1+j}_{t=0} E^{i+1,j}_tg_t \nonumber \\
            &= \left(x_P -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)\right)\Omega_{ij} \nonumber \\
            &= \suml{t=0}{i+j} E^{ij}_t\left(x_P -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)\right) g_t \nonumber \\
            &= \suml{t=0}{i+j} E^{ij}_t\left(\left(tg_{t-1} +
            \frac{1}{2(\alpha+\beta)}g_{t+1}\right) -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)g_t\right) \nonumber \\
            &= \suml{t=0}{i+j} \left((t+1)E^{ij}_{t+1} +
            \frac{1}{2(\alpha+\beta)}E^{ij}_{j-1} -
            \frac{\beta}{\alpha+\beta}(A_x-B_x)\right)g_t
            \label{eq:omegaIncr}
        \end{align}
    Using the properties listed in \Arf{eq:hermiteGaussProp}(mainly the
    recurrence) and the expansion \Arf{eq:omegaDef}. The incrementation of $j$
    follows the exact same derivation. The starting coefficient is thus
        \begin{equation}
            E^{00}_0 = K_{AB}
        \end{equation}
    This is found by inserting in $i=j=0$ into \Arf{eq:omegaIncr}, realizing
    the exponental is the same for all $i$ and $j$ and using the orthogonality
    between the Hermite-Gaussians\footnote{Another way of expressing this
    statement is to say that each index $t$ in the sum corresponds to an
    equation for $E^{ij}_t$.}. The recurrent coupled relations for the
    $E$'s are
        \begin{equation}
            \begin{aligned}
                E^{i+1,j}_t &= \frac{1}{2(\alpha + \beta)}E^{ij}_{t-1} -
                \frac{\beta}{\alpha+\beta}(A_x - B_x)E^{ij}_t +
                (t+1)E^{ij}_{t+1} \\
                E^{i,j+1}_t &= \frac{1}{2(\alpha + \beta)}E^{ij}_{t-1} -
                \frac{\alpha}{\alpha+\beta}(A_x - B_x)E^{ij}_t +
                (t+1)E^{ij}_{t+1}
            \end{aligned}
        \end{equation}
    The overlap distribution can with this be expanded in Hermite-Gaussian
    functions.

    As mentioned, the whole point of using Hermite-Gaussian functions is
    because of the inherent definition with the derivative with respect to the
    centering(remember s-types). This means that for attaining the final
    expression we must in the end differentiate the expansion coefficients. We
    state here the coefficients differentiated with respect to the difference
    variable $Q_x=A_x-B_x$
        \begin{equation}
            \begin{aligned}
                E^{00;n+1}_0 &=
                -\frac{2\alpha\beta}{\alpha+\beta}\left(Q_xE^{00;n}_0 +
                nE^{00;n-1}_0\right) \\
                E^{i+1,j;n}_t &= \frac{1}{2(\alpha+\beta)}E^{ij;n}_{t-1} -
                \frac{\beta}{\alpha+\beta}\left(Q_xE^{ij;n}_t +
                nE^{ij;n-1}_t\right) + (t+1)E^{ij;n}_{t+1} \\
                E^{i,j+1;n}_t &= \frac{1}{2(\alpha+\beta)}E^{ij;n}_{t-1} -
                \frac{\alpha}{\alpha+\beta}\left(Q_xE^{ij;n}_t +
                nE^{ij;n-1}_t\right) + (t+1)E^{ij;n}_{t+1} \\
                E^{ij;n}_t &\equiv \frac{\prtl^n E^{ij}_t}{\prtl Q^n_x}
            \end{aligned}
        \end{equation}
    Notice that these expressions are just the same relations as for the
    coefficients, but with an extra factor in the middle.

\subsection{Overlap Integral\label{susec:overlapIntegral}}
    With The simplification to s-types and the product rule, the integration
    may begin. Starting with the overlap $\Braket{i|j}$ and using
    \Arf{eq:omegaDef}\footnote{Also using the following integral $\infint
    \me^{-\lambda x^2} = \sqrt{\frac{\pi}{\lambda}},\indent \lambda>0$. >>REF
    ROTTMANN<<}
        \begin{align}
            \Braket{i|j} &= \infint
            \Omega_{ij}(\alpha_p,\beta_p,\blds{r},\blds{A},\blds{B}) \md
            \blds{r} \nonumber \\
            &= \sumE{p}{i}{j} \infint g_p(\alpha,\beta,\blds{r},\blds{P})
            \md\blds{r} \nonumber \\
            &= \sumE{p}{i}{j} \infint (\blds{r}-\blds{P})^p \me^{-(\alpha_p +
            \beta_p)(\blds{r} - \blds{P})^2} \md\blds{r} \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^d
            \label{eq:stypeOverlap}
        \end{align}
    The power $d$ comes from splitting the integral into the $d$ dimensions.
    Also using the \txtit{multi-index
    notation}(\Arf{sec:multiIndexNotation})\footnote{The power $d$ also means
    that with the multi-index notation the entire expression in the paranthesis
    are to be calculated for each dimension in $p$ and then multiplied
    together.} and expanding
        \begin{equation}
            E^{ab}_{n} = \prod_d E^{a_db_d}_{n_d}
            \label{eq:Enotation}
        \end{equation}
    Such that the coefficients are all just products over coefficients in each
    dimension. A substitution in each dimension(i.e $u=x-P_x$) is also used.
    Notice in addition that the scaling factors $\alpha$ and $\beta$ are
    specific for each $p$ because of the overlap expansion.

\subsection{Potential Integral}
    The second integral with the $x^k_d$ part shows up in the external
    potential part of the Hamiltonian and again with the Gaussian product rule
    the expression gives
        \begin{align}
            \Braket{i|x^k_d|j} &= \infint x^{k}_d
            \Omega_{ij}(\alpha_p,\beta_p,\blds{r},\blds{A},\blds{B}) \md
            \blds{r} \nonumber \\
            &= \sumE{p}{i}{j} \infint x^k_d (\blds{r}-\blds{P})^p
            \me^{-(\alpha_p+\beta_p)(\blds{r} - \blds{P}_p)^2} \md \blds{r}
            \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^{D-1} \infint
            (u+P_d)^k\exp(-(\alpha_p+\beta_p)u^2) \md u \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^{D-1}
            \sum\limits_{l=0}^k {k\choose l} P^{k-l}_d \infint
            u^l\exp(-(\alpha_p+\beta_p)u^2) \md u \nonumber \\
            &= \sumE{p}{i}{j}
            \left(\frac{\left((-1)^p-1\right)\Gamma\left(\frac{p+1}{2}\right)}
            {2(\alpha_p+\beta_p)^{\frac{p+1}{2}}}\right)^{D-1}
            \sum\limits_{l=0}^k {k\choose l}
            \frac{P^{k-l}_d}{2(\alpha_p+\beta_p)^{\frac{l}{2}}}
            \left((-1)^l+1\right) \Gamma\left(\frac{l+1}{2}\right)
            \label{eq:potIntegral}
        \end{align}
    The integrals are split in each dimension and the dimensions not equal to
    $d$(in $x^k_d$) are pulled out and the approach in \Arf{eq:stypeOverlap} is
    applied. The integral over dimension $d$ is then substituted with
    $u=x_d+P_d$. In line four $(u+P_d)^k$ is rewritten with the \txtit{binomial
    expansion}\footnote{The integral $\infint x^n\me^{-ax^2}\md x =
    \frac{1}{2}a^{-\frac{n}{2}}\Gamma\left(\frac{k+1}{2}\right),\indent n>-1,
    n\;\text{even}$, >> REF THIS <<< is used as well.}.

\subsection{Laplacian Integral}
    The third integral with the Laplacian operator arises in the kinetic part
    of the Hamiltonian. This integral can be expressed in terms of
    \Arf{eq:stypeOverlap}, the overlap integral, however the Laplacian applied
    to a Hermite-Gaussian has to be calculated first
        \begin{align}
            \nabla^2 g_i(\alpha;\blds{r},\blds{A}) &= \sum_d \prd{x_d}[][2]
            \left(\prod_{d'} \left(x - A_{d'}\right)^{i_{d'}}_{d'} \exp(-\alpha
            \left(x_{d'} - A_{d'}\right)^2)\right)\nonumber \\
            &= \sum_d \prod_{d'\neq d} g_{i,d'} \prd{x_d}[][2]\left(\left(x_d -
            A_d\right)^{i_d} \exp(-\alpha \left(x_d - A_d\right)^2)\right)
            \nonumber \\
            &= \sum_d \prod_{d'\neq d} g_{i,d'} g_{i,d}
            \left(4\alpha^2\left(x_d-A_d\right)^{i_d+2} -
            2\alpha\left(2i_d+1\right)\left(x_d-A_d\right)^{i_d} +
            i_d\left(i_d-1\right)\left(x_d-A_d\right)^{i_d-2}\right) \nonumber
            \\
            &= g_i\sum_d \left(4\alpha^2\left(x_d-A_d\right)^{i_d+2} -
            2\alpha\left(2i_d+1\right)\left(x_d-A_d\right)^{i_d} +
            i_d\left(i_d-1\right)\left(x_d-A_d\right)^{i_d-2}\right)
        \end{align}
    Now for the integral we have
        \begin{align}
            \Braket{i|\nabla^2|j} &= \infint
            g_i(\alpha;\blds{r},\blds{A})\nabla^2g_j(\beta;\blds{r},\blds{B}) 
            \md\blds{r} \nonumber \\
            &= \sum_d\prod_{d'\neq d}
            \Braket{i_{d'}|\sigma_{d'}(S_d(\beta;x-B_d))|j_{d'}}
            \label{eq:laplacianIntegral}
        \end{align}
    with
        \begin{equation}
            \begin{aligned}
                S_d(\alpha;x_d-A_d) &\equiv
                \left(4\alpha^2\left(x_d-A_d\right)^{i_d+2} -
                2\alpha\left(2i_d+1\right)\left(x_d-A_d\right)^{i_d} +
                i_d\left(i_d-1\right)\left(x_d-A_d\right)^{i_d-2}\right) \\
                \sigma_d(S_d) &\equiv \left\{\begin{matrix}
                                            1,&\indent d' \neq d \\
                                            S_d,&\indent d' = d
                                            \end{matrix}
                                        \right.
            \end{aligned}
        \end{equation}
    meaning the Laplacian integral can be expressed in terms of the overlap
    integrals $\Braket{i|j+2}$, $\Braket{i|j}$ and
    $\Braket{i|i-2}$\footnote{Since $xg_i=g_{i+1}$ and
    $\frac{g_i}{x}=g_{i-1}$.}.

\subsection{Coulomb Potential Integral}
    Lastly, the troublesome\footnote{Damn inverse term prevents dimensional
    decomposition.} Coulomb integral needs to be calculated. Due to the $1/r$
    term we cannot split the integral in each respective dimension as
    previously. Before we approach the full Coulomb integral, lets calculate a
    simpler integral over a so-called \txtit{Coulomb Potential distribution}
        \begin{equation}
            \infint \me^{-\alpha\left(\blds{r} - \blds{A}\right)^2}
            \frac{1}{\abs{\blds{r} - \blds{B}}} \md\blds{r}
        \end{equation}
    The calculation of this integral will be beneficial for the calculation of
    the Coulomb integral as we can reuse most of the tricks used. With
    \Arf{eq:gaussianProductRule}, the Gaussian product rule, in mind. We
    rewrite the inverse term with
        \begin{equation}
            \infint \me^{r^2_B t^2} \md t = \frac{\sqrt{\pi}}{r_B} \Rarr
            \frac{1}{r_B} = \frac{1}{\sqrt{\pi}} \infint \me^{r^2_Bt^2} \md t
            \label{eq:onelectronTrick1}
        \end{equation}
    The Coulomb potential integral is thus, with
    \Arf{eq:gaussianProductRule}(again the product rule)
        \begin{align}
            \infint\infint \me^{-\alpha\left(\blds{r} - \blds{A}\right)^2}
            \frac{1}{\abs{\blds{r} - \blds{B}}} \md\blds{r} &=
            \frac{1}{\sqrt{\pi}}\infint \me^{-\alpha\left(\blds{r} -
            \blds{A}\right)^2} \me^{t^2(\blds{r} - \blds{B})^2} \md\blds{r} \md
            t \nonumber \\
            &= \frac{1}{\sqrt{\pi}} \infint\infint \me^{-\frac{\alpha
            t^2}{\alpha + t^2}\left(\blds{A} - \blds{B}\right)^2}
            \me^{-(\alpha+t^2)r^2_S} \md\blds{r} \md t \nonumber \\
            &= \frac{1}{\sqrt{\pi}} \infint \left(\frac{\pi}{\alpha +
            t^2}\right)^{\frac{d}{2}} \me^{-\frac{\alpha t^2}{\alpha +
            t^2}\left(\blds{A} - \blds{B}\right)^2} \md t
            \label{eq:coulombPotentialIntegral}
        \end{align}
    The integral over $t$ has to be addressed separately for two- and three
    dimensions. For the three-dimensional case the reader is referred to >> REF
    HELGAKER <<. Here we will derive a closed-form form expression for the
    two-dimensional case. First let us use the following substitution
        \begin{equation}
            \begin{aligned}
                u &= \frac{t}{\sqrt{\alpha+t^2}} \\
                t &= u\sqrt{\frac{\alpha}{1-u^2}} \\
                \frac{\md u}{\md t} &= \frac{\alpha}{(\alpha + t^2)^{\frac{3}{2}}} \\
                \lim\limits_{t\rarr -\infty} u(t) &= -1 \\
                \lim\limits_{t\rarr \infty} u(t) &= 1 \\
            \end{aligned}
            \label{eq:uSubs1}
        \end{equation}
    The integrand(ignoring the exponential part) is then
        \begin{align}
            \frac{\md t}{\alpha + t^2} &= \frac{1}{\alpha + t^2} \frac{(\alpha +
            t^2)^{\frac{3}{2}}}{\alpha} \md u \nonumber \\
            &= \frac{\sqrt{\alpha + t^2}}{\alpha} \md u \nonumber \\
            &= \frac{t}{\alpha u} \md u \nonumber \\
            &= \frac{1}{\alpha u} u\sqrt{\frac{\alpha}{1-u^2}} \md u \nonumber \\
            &= \frac{1}{\sqrt{\alpha}}\sqrt{\frac{1}{1-u^2}} \md u
        \end{align}
    giving
        \begin{align}
            I_{\text{2D}} = \sqrt{\frac{\pi}{\alpha}}\int\limits^1_{-1}
            \frac{1}{\sqrt{1-u^2}} \me^{-\alpha u^2\abs{\blds{A} - \blds{B}}^2}
            \md u
            \label{eq:oneElectron2D}
        \end{align}
    and for the three-dimensional case we have a simpler form(easily seen with
    the same substitution)
        \begin{align}
            I_{\text{3D}} = \pi\int\limits^1_{-1} \me^{-\alpha u^2\abs{\blds{A}
            - \blds{B}}^2} \md u
            \label{eq:oneElectron3D}
        \end{align}
    These integrals must be solved numerically. One can also rewrite the
    2D-integral in terms of the \txtit{Modified Bessel function of first kind}
    by using $u^2=1/2(1 - \cos(\theta)$ >> REF WOLFRAM(MATHWORKS) <<. The
    3D-integral can be rewritten with an \txtit{incomplete Gamma function}
    >>REF HELGAKER<<. From \Arf{eq:centerDerGauss}, the integrals have to be
    differentiated in order to get the final closed form expressions, see
    \Arf{sub:445}.

\subsection{Coulomb Interaction Integral}
    In the previous section an expression for integral over a Coulomb potential
    was derived. Before we embark into handling the full Coulomb interaction
    integral, another exercise with simpler interaction integral is worthwhile.
    The integral in question is
        \begin{equation}
            I' = \infint\infint \me^{-\alpha(\blds{r'}-\blds{A})^2}
            \me^{-\beta(\blds{r}-\blds{B})^2} \frac{1}{\abs{\blds{r'} -
            \blds{r}}} \md\blds{r} \md\blds{r'}
            \label{eq:coulombInteractionSimple}
        \end{equation}
    This is an interaction between two distributions. Firstly, notice that we
    can rewrite the distribution centered in $\blds{A}$ and the Coulomb
    interaction with the previously calculated Coulomb potential integral given
    in \Arf{eq:coulombPotentialIntegral}. Using $I$ as a general label for
    \Arf{eq:oneElectron2D,eq:oneElectron3D} we have
        \begin{align}
            I' &= \infint\infint \me^{-\alpha(\blds{r'}-\blds{A})^2}
            \me^{-\beta(\blds{r}-\blds{B})^2} \frac{1}{\abs{\blds{r'} -
            \blds{r}}} \md\blds{r} \md\blds{r'} \nonumber \\
            &= \infint I_D(\alpha;\abs{\blds{r}-\blds{A}}) \me^{-\beta(\blds{r}
            - \blds{B})^2} \md\blds{r}
            \label{eq:Cintr1}
        \end{align}
    Inserting in the definition for $u$(the substitution in \Arf{eq:uSubs1})
    and using the extremely useful Gaussian product rule for the product
    between the distribution centered in $\blds{B}$ and the exponential factor
    in $I$(which is labelled the same for both the two- and three dimensional
    case) is
        \begin{equation}
            \me^{-\alpha u^2(\blds{r}-\blds{A})^2} \me^{-\beta(\blds{r} -
            \blds{B})^2} = \me^{-(\alpha u^2 + \beta)\blds{r_S}^2}
            \me^{-\frac{\alpha u^2\beta}{\alpha u^2 + \beta}
            (\blds{A}-\blds{B})^2}
        \end{equation}
    Inserting this into \Arf{eq:Cintr1} with
        \begin{equation}
            \upsilon \equiv \left\{
                \begin{matrix}
                    \sqrt{\frac{\pi}{\alpha}}\sqrt{\frac{1}{1-u^2}},&\indent
                    \text{2D} \\
                    \pi,&\indent \text{3D}
                \end{matrix}\right.
        \end{equation}
    we have
        \begin{align}
            I' &= \infint \int\limits^1_{-1} \upsilon \me^{-(\alpha u^2 +
            \beta)\blds{r_S}^2} \me^{-\frac{\alpha u^2\beta}{\alpha u^2 +
            \beta} (\blds{A}-\blds{B})^2} \md\blds{r}\md u \nonumber \\
            &= \int\limits^1_{-1} \upsilon \left(\frac{\pi}{\alpha u^2 +
            \beta}\right)^{\frac{d}{2}} \me^{-\frac{\alpha u^2\beta}{\alpha u^2
            + \beta}(\blds{A}-\blds{B})^2} \md u
        \end{align}
    Specializing to the two-dimensional case and substituting
        \begin{equation}
            \begin{aligned}
                v &= u\sqrt{\frac{\alpha+\beta}{\alpha u^2 + \beta}} \\
                \frac{\md v}{\md u} &= \frac{\beta\sqrt{\alpha+\beta}}{(\alpha
                u^2 + \beta)^{3/2}} \\
                u &= v \sqrt{\frac{\beta}{\alpha+\beta - \alpha v^2}} \\
                v(-1) &= -1 \\
                v(1) &= 1
            \end{aligned}
        \end{equation}
    The integrand is
        \begin{align}
            \frac{1}{\sqrt{1 - u^2}} \frac{1}{\alpha u^2 + \beta} \md u &=
            \frac{1}{\sqrt{1-u^2}} \frac{1}{\alpha u^2 + \beta} \frac{(\alpha
            u^2 + \beta)^{3/2}}{\beta\sqrt{\alpha+\beta}}\md v \nonumber \\
            &= \frac{1}{\sqrt{1-u^2}} \frac{u}{\beta v}\md v \nonumber \\
            &= \sqrt{\frac{\alpha+\beta -\alpha
            v^2}{(\alpha+\beta)(1-v^2)}}\frac{1}{\beta
            v}v\sqrt{\frac{\beta}{\alpha+\beta-\alpha v^2}} \md v \nonumber \\
            &= \frac{1}{\sqrt{\beta(\alpha+\beta)}} \frac{1}{\sqrt{1 - v^2}}
            \md v
        \end{align}
    we have
        \begin{equation}
            I'_{\text{2D}} =
            \frac{\pi^{\frac{3}{2}}}{\sqrt{\alpha\beta(\alpha+\beta)}}
            \int\limits^{1}_{-1} \frac{1}{\sqrt{1 - v^2}}
            \me^{-\frac{\alpha\beta}{(\alpha + \beta)}v^2(\blds{A}-\blds{B})^2}
            \md v
            \label{eq:coulombInteractionSimpleFinal}
        \end{equation}
    This expression will be of great use when calculating the final full
    interaction integral over the Coulomb distribution. The next section will
    derive the mentioned recurrence relation before the full Coulomb integral
    is calculated

\subsection{Recurrence Relation\label{sub:445}}
    Following >>REF HELGAKER<<, we proceed with finding a similar recurrence
    relation for the derivatives. We define a function containing the integral
    which needs to be solved numerically
        \begin{equation}
            \begin{aligned}
                \zeta_n(x) &\equiv \int\limits^1_{-1} \frac{u^{2n}}{\sqrt{1 -
                u^2}} \me^{-u^2x} \md u \\
                \prd{x}[\zeta_n] &= -\zeta_{n+1}
            \end{aligned}
            \label{eq:zetaDef}
        \end{equation}
    The Coulomb potential integral is then, in terms of $\zeta_n(x)$
        \begin{equation}
            \twoDI = \sqrt{\frac{\pi}{\alpha}} \zeta_0\left(\alpha
            R^2_{AB}\right)
        \end{equation}
    and the first derivative with respect to $A_x$ is
        \begin{align}
            \prd{A_x}[\twoDI] &= \sqrt{\frac{\pi}{\alpha}} \prd{A_x}
            \zeta_0\left(\alpha R^2_{AB}\right) \nonumber \\
            &= -2\sqrt{\alpha\pi}X_{AB}\zeta_1\left(\alpha R^2_{AB}\right)
        \end{align}
    With this we define an auxiliary function
        \begin{equation}
            \begin{aligned}
                \xi^n_{tu} &=\prdp{A_x}{t}\prdp{A_y}{u} \xi^n_{00} \\
                \xi^n_{00} &= (-2)^n\alpha^{n-\frac{1}{2}} \zeta_n\left(\alpha
                R^2_{AB}\right)
            \end{aligned}
            \label{eq:auxiliary2d1}
        \end{equation}
    and take a look at the incrementation of $t$
        \begin{align}
            \xi^n_{t+1,u} &= \prdp{A_x}{t}\prdp{A_y}{u} \prd{A_x}[\xi^n_{00}]
            \nonumber \\
            &= \prdp{A_x}{t}X_{AB}\xi^{n+1}_{0u}
            \label{eq:Rtincr}
        \end{align}
    Using the commutator between
    $\prtl^t_{A_x}$\footnote{$\prtl^t_x=\prd{x}[][t]$}
        \begin{align}
            \prd{A_x}[][t] X_{AB} &= \left[\prd{A_x}[][t], X_{AB}\right] +
            X_{AB}\prd{A_x}[][t] \nonumber \\
            &= t\prd{A_x}[][t-1] + X_{AB}\prd{A_x}[][t]
        \end{align}
    the final form of \Arf{eq:Rtincr} is\footnote{The incrementation of $u$ is
    derived in the exact same manner as with $t$.}
        \begin{equation}
            \begin{aligned}
                \xi^n_{t+1,u} &= t\xi^{n+1}_{t-1,u} + X_{AB}\xi^{n+1}_{t,u} \\
                \xi^n_{t,u+1} &= u\xi^{n+1}_{t,u-1} + Y_{AB}\xi^{n+1}_{t,u}
            \end{aligned}
        \end{equation}
    With this all Hermite integrals of order $t+u\leq N$ can be calculated from
    $\zeta$ of order $n\leq N$, the only difference being $X_{AB}$ and
    $Y_{AB}$. The Coulomb interaction integral
    (\Arf{eq:coulombInteractionSimpleFinal}) follows this exact recurrence, but
    with a different proportionality factor $\alpha\beta/(\alpha+\beta)$. We
    will write it out for the sake of clarity
        \begin{equation}
            \begin{aligned}
                \prd{A_x}[I'_{\text{2D}}] &= -\frac{2\alpha\beta}{\alpha+\beta}
                X_{AB}\zeta_1\left(\frac{\alpha\beta}{\alpha+\beta}R^2_{AB}\right)
                \\
                \xi^n_{00} &= \left(\frac{-2\alpha\beta}{\alpha+\beta}\right)^n
                \zeta_n\left(\frac{\alpha\beta}{\alpha+\beta} R^2_{AB}\right)
            \end{aligned}
            \label{eq:recurrInteraction}
        \end{equation}
    Notice that the only difference between the obtained recurrence relations
    and the ones obtained by Helgaker >> REF HELGAKER << is in
    \Arf{eq:auxiliary2d1} and \Arf{eq:recurrInteraction}. Other than this the
    incrementation of $\zeta_n$ gives the exact same $X_{AB}$(and similar for
    the other directions) as with the incomplete gamma function.

% \subsection{Overlap Distribution Integral}
%     We have already calculated the overlap integrals directly in
%     \Arf{susec:overlapIntegral} however, in order to calculate the full Coulomb
%     integrals a polynomial expansion of the Hermite-Gaussians is needed for
%     finding a closed-form expression. The polynomials in questian are the
%     well-known Hermite polynomials >> REF MOTIVATION HERMITE <<
% 
%     This concludes the pre-calculations needed in order to find a closed-form
%     expression for the Coulomb distribution integral. The next chapter will
%     handle just that.

\subsection{Coulomb Distribution Integral}
    With the derived expressions for the Coulomb potential integral the full
    two-body distribution can be treated. The expression with the
    simplification in \Arf{eq:centerDerGauss} gives
        \begin{align}
            \Braket{ij|\frac{1}{r_{12}}|kl} &= \infint\infint
            \Omega_{ik}(\blds{\alpha},\blds{\gamma},\blds{r_1},
            \blds{A},\blds{C}) \frac{1}{\abs{\blds{r_1} - \blds{r_2}}}
            \Omega_{jl}(\blds{\beta},\blds{\delta},\blds{r_2},
            \blds{B},\blds{D}) \md\blds{r_1} \md\blds{r_2} \nonumber \\
            &= \suml{pq}{i+k,j+l} E^{ik}_pE^{jl}_q \infint\infint
            \frac{g_{p}(\alpha+\gamma,\blds{r_1},\blds{P})
            g_{q}(\beta+\delta,\blds{r_2},\blds{Q})}{\abs{\blds{r_1} -
            \blds{r_2}}} \md\blds{r_1} \md\blds{r_2}\nonumber \\
            &= \frac{\pi^{d-\frac{1}{2}}}{\sqrt{(\alpha+\gamma)(\beta+\delta)
            (\alpha+\gamma+\beta+\delta)}} \suml{pq}{i+k,j+l} E^{ik}_pE^{jl}_q
            (-1)^{q} \xi_{p+q}\left(\frac{(\alpha + \gamma)(\beta +
            \delta)}{\alpha + \gamma + \beta + \delta},\blds{R_{S_1S_2}}\right)
            \label{eq:coulomb_dist_integral_stype}
        \end{align}
    Where we have used the multi-index\footnote{Essentially just expanding an
    index in each dimension, for instance $i=(i_x,i_y,i_z)$ with corresponding
    $p=(p_x, p_y, p_z)$ with each index inside the tuple running to each
    respective index, meaning for instance $p_x=0$ to $i_x$ and so on.}
    notation for $p$, $q$, $i$, $k$, $j$, and $l$ \Arf{eq:Enotation}
    and used \Arf{eq:coulombInteractionSimpleFinal} to arrive at the final
    step. An additional simplification due to the fact that $\zeta_n$ is only
    dependant on the relative distance of the centers is also used, for the
    x-coordinate it is stated as
        \begin{equation}
            \prdp{P_x}{p_x}\prdp{Q_x}{q_x} = (-1)^{p_x+q_x} \prdp{P_x}{p_x+q_x}
        \end{equation}
    and the same for the other directions.

\section{Double-Well Functions}
    This section will explain the building of a basis for the
    \txtit{double-well potential}. We will expand them in a linear combination
    of harmonicoscillator functions and find the coefficients of this expansion
    by solving the arising eigenvalue-problem. Let us first express the
    potential
        \begin{equation}
            \UDW(r) = \VHO(r) + \VDW_n(r)
            \label{eq:UDW}
        \end{equation}
    A double well potential is essentially just a perturbation of the usual
    Harmonicoscillator potential(which is a single-well). The $\VDW_n$ part is
    assumed to a polynomial of degree $n$. This means that the integral over
    such a potential can be calculated using \Arf{eq:potIntegral}.

\subsection{The Eigenvalue problem}
    The mentioned eigenvalue problem comes from the basis expansion of the
    spacial part and from the trick of projecting with a single function from
    left. We will explain briefly. First let us express the expansion,
        \begin{equation}
            \ket{\psiDW_p} = \sumll{l}C_{lp}\ket{\psiHO_l}
        \end{equation}
    and then project from left the bra $\bra{\psiHO_k}$ in the
    inner-product space of $h^{\text{DW}}$
        \begin{equation}
            \Braket{\psiHO_k|\hDW|\psiDW_p} =
            \sumll{l}C_{pl}\Braket{\psiHO_k|\hDW|\psiHO_l} =
            \sumll{l}C_{pl}\varepsilon^{\text{DW}}_l
        \end{equation}
    This gives us an eigenvalue equation
        \begin{equation}
            \blds{H}\blds{C} = \blds{\varepsilon^{\text{DW}}}\blds{C}
        \end{equation}
    with
        \begin{equation}
            H_{ij} = \Braket{\psiHO_i|h^{\text{DW}}|\psiHO_j}
        \end{equation}
    Using \Arf{eq:UDW} we can write $H_{ij}$ as
        \begin{equation}
            H_{ij} = \veps^{\text{HO}}_i\delta_{ij} +
            \Braket{\psiHO_i|\VDW_n|\psiHO_j}
        \end{equation}
    by using the solution to Schrödinger's equation for the harmonic oscillator
    system. \\

    We are now in a position to build a basis for the double-well system by
    reusing all the results and expressions concerning the single-well system.
    The only difference is the extra integral over $\VDW_n$ where $n$ would be
    larger than $2$(as is the case with the harmonic oscillator potential). \\

    For clarity let us also write out the expression for the resulting
    Hartree-Fock basis to be used with the Variational Monte-Carlo method.
        \begin{equation}
            \psi^{\text{HF}}_p = \sumll{kl} C^{\text{HF}}_{pk}C_{kl}\psiHO_l
        \end{equation}

    The procedure of diagonalizing $H_{ij}$ also gives an additional set of
    energies we can use. The full form of the integral-elements involved in
    Hartree-Fock is thus
        \begin{equation}
            \begin{aligned}
                \Braket{\psiDW_p|\psiDW_q} &= \delta_{pq}
                \varepsilon^{\text{DW}}_p\delta_{pq} \\
                \Braket{\psiDW_p|h^{\text{DW}}|\psiDW_q} &=
                \varepsilon^{\text{DW}}_p\delta_{pq} \\
                \Braket{\psiDW_p\psiDW_q|\frac{1}{r_{12}}|\psiDW_r\psiDW_s} &=
                \suml{tuvw}{ijkl} C_{tp}C_{uq}C_{vr}C_{ws}
                \Braket{\psiHO_t\psiHO_u|\frac{1}{r_{12}}|\psiHO_v\psiHO_w}
            \end{aligned}
        \end{equation}
    Where the two-body elements over the harmonic oscillator functions can be
    calculated by expansion in s-type Gaussian constituents and then using
    \Arf{eq:coulomb_dist_integral_stype}.

\subsection{Choosing the Basis Functions}
    In order to actually solve the eigenvalue equation we use \text{Python} and
    the \text{NumPy} package, however we still need to choose the $\psiHO$'s
    first. This will be experimented with and we will choose enough to reach to
    \txtit{Hartree-Fock limit}. The choice will also follow the
    Harmonicoscillator levels in terms of degeneracy(see \Arf{subfig:3Dspin,
    subfig:2Dspin}). This means for instance that if we choose to only use $1$
    spacial function we only need the ground-state function, but there is no
    reason to believe that the electron-configuration would prefer any two(or
    $3$ in 3D) of the functions in the second level over one another. This
    means that we choose the basisfunctions according to the \txtit{magic
    numbers} of the Harmonicoscillator system basis.

\subsection{Degeneracy}
    When we tackled the single-well problem the energy-levels were degenerate
    and followed the magic numbers. For the double-well only the degeneracy due
    to spin is present. This means that we can(still with two-spin fermions)
    run the simulations with $N=2,4,6,\dots$ instead of the original
    $N=2,6,12,20,\dots$ in two dimensions and $N=2,8,20,30\dots$ in three.
